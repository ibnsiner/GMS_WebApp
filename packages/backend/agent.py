import google.generativeai as genai
import json
import os
import uuid
import logging
from neo4j import GraphDatabase
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime

# --- ë¡œê¹… ì„¤ì • ---
# ì½˜ì†”ì—ë§Œ ë¡œê·¸ ì¶œë ¥ (íŒŒì¼ ìƒì„± ì•ˆ í•¨)
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s][%(levelname)s] %(message)s',
    handlers=[
        logging.StreamHandler()  # ì½˜ì†” ì¶œë ¥ë§Œ
    ]
)

# matplotlib ë¡œê·¸ ë ˆë²¨ì„ WARNINGìœ¼ë¡œ ì„¤ì • (í°íŠ¸ ê²€ìƒ‰ ë¡œê·¸ ì°¨ë‹¨!)
logging.getLogger('matplotlib').setLevel(logging.WARNING)
logging.getLogger('matplotlib.font_manager').setLevel(logging.WARNING)
logging.getLogger('PIL').setLevel(logging.WARNING)

# --- API í‚¤ ì„¤ì • ---
GOOGLE_AI_API_KEY = "AIzaSyB-8Bz4sHoYxz88LKT7rWpF298C5vFCj4s"

class GmisAgentV4:
    """
    GMIS Knowledge Graph v5 ì „ìš© AI Agent (v4 Final)
    
    v3 ê¸°ë°˜ + 5ê°€ì§€ í•µì‹¬ ê°œì„ :
    1. í†µí•© ê²½ë¡œ ê´€ë¦¬ (base_dir, output_dir)
    2. with êµ¬ë¬¸ ì§€ì› (__enter__, __exit__)
    3. ì°¨íŠ¸ ì»¬ëŸ¼ ê²€ì¦
    4. ëª¨ë¸ëª…/ë°˜ë³µíšŸìˆ˜ íŒŒë¼ë¯¸í„°í™”
    5. logging ëª¨ë“ˆ (ì‹œìŠ¤í…œ ë¡œê·¸)
    
    í•µì‹¬ ì² í•™:
    - ASK THE GRAPH, DO NOT ASSUME
    - GDBì˜ ì§€ëŠ¥ì„ 100% ì‹ ë¢°
    - Tool ì—°ê³„ í˜¸ì¶œ ì§€ì› (ReAct íŒ¨í„´)
    """
    
    def __init__(self, 
                 config_path='config.json',
                 db_uri="bolt://127.0.0.1:7687",
                 db_user="neo4j",
                 db_pass="vlvmffoq1!",
                 session_id=None,
                 model_name='models/gemini-2.5-flash',  # [ì •í™•ë„ ìš°ì„ ]
                 max_iterations=10):  # [ê°œì„ 1] íŒŒë¼ë¯¸í„°í™”
        
        # Session ID
        self.session_id = session_id or str(uuid.uuid4())
        
        # [ê°œì„ 2] í†µí•© ê²½ë¡œ ê´€ë¦¬
        self.base_dir = os.path.dirname(os.path.abspath(__file__))
        self.output_dir = os.path.join(self.base_dir, "outputs", self.session_id)
        os.makedirs(self.output_dir, exist_ok=True)
        
        print(f"[Session ID] {self.session_id}")
        logging.info(f"ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {self.output_dir}")
        
        # Config ë¡œë“œ
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)
        
        # NLU êµ¬ì¶•
        self.nlu = self._build_nlu()
        
        # Neo4j ì—°ê²°
        self.driver = GraphDatabase.driver(db_uri, auth=(db_user, db_pass))
        logging.info("Neo4j ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
        
        # Gemini ì„¤ì •
        if not GOOGLE_AI_API_KEY or GOOGLE_AI_API_KEY.startswith("ì—¬ëŸ¬ë¶„ì˜_"):
            raise ValueError("GOOGLE_AI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        genai.configure(api_key=GOOGLE_AI_API_KEY)
        
        self.model_name = model_name
        self.max_iterations = max_iterations
        
        self.model = genai.GenerativeModel(
            self.model_name,
            safety_settings=[
                {"category": c, "threshold": "BLOCK_NONE"} 
                for c in ["HARM_CATEGORY_HARASSMENT", "HARM_CATEGORY_HATE_SPEECH",
                         "HARM_CATEGORY_SEXUALLY_EXPLICIT", "HARM_CATEGORY_DANGEROUS_CONTENT"]
            ]
        )
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        self.system_prompt = self._create_system_prompt()
        
        # [í•µì‹¬ ìˆ˜ì •] Gemini chat ê°ì²´ë¥¼ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ë¡œ ìœ ì§€
        self.chat = None  # ì²« run() í˜¸ì¶œ ì‹œ ì´ˆê¸°í™”
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ (Gemini API í˜•ì‹)
        self.chat_history = []
        self.max_history_turns = 20  # íˆìŠ¤í† ë¦¬ ì œí•œ ì™„í™” (ìš”ì•½ ê¸°ëŠ¥ ë¹„í™œì„±í™”)
        
        # ë§ˆì§€ë§‰ ì¿¼ë¦¬ ê²°ê³¼ ìºì‹± (ì‹¤ì œ ë°ì´í„°ëŠ” ì—¬ê¸°ì—)
        self.last_query_result = None
        
        # ë§ˆì§€ë§‰ ì°¨íŠ¸ ë°ì´í„° ìºì‹± (íŒŒì‹± ì‹œ ì‚¬ìš©)
        self.last_chart_data = None
        
        # ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ê¸°ë³¸: False)
        self._batch_test_mode = False
        
        print(f"[OK] Agent v4 ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: {self.model_name})")
    
    # [ê°œì„ 3] with êµ¬ë¬¸ ì§€ì›
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()
    
    def _build_nlu(self):
        """ì™„ì „í•œ NLU ì‚¬ì „ êµ¬ì¶• (v3 ë™ì¼)"""
        nlu = {
            "company": {},
            "account": {},
            "group": {},
            "ratio": {},
            "viewpoint": {},
            "temporal_relation": {},
            "temporal_unit": {},
            "analysis_type": {},
            "comparison_type": {}  # ìƒˆë¡œ ì¶”ê°€: ê³„íš-ì‹¤ì  ë¹„êµ
        }
        
        # íšŒì‚¬ ë³„ì¹­
        for cid, data in self.config.get('entities', {}).get('companies', {}).items():
            for alias in [data.get('official_name')] + data.get('aliases', []):
                if alias:
                    nlu["company"][alias.lower()] = cid
        
        # ê³„ì • ë³„ì¹­
        for aid, data in self.config.get('entities', {}).get('accounts', {}).items():
            for alias in [data.get('official_name')] + data.get('aliases', []):
                if alias:
                    nlu["account"][alias.lower()] = aid
        
        # ê·¸ë£¹ ë³„ì¹­
        for gid, data in self.config.get('business_rules', {}).get('company_groups', {}).items():
            for alias in [data.get('name')] + data.get('aliases', []):
                if alias:
                    nlu["group"][alias.lower()] = gid
        
        # ì¬ë¬´ë¹„ìœ¨
        for rid, data in self.config.get('financial_ratios', {}).get('ratios', {}).items():
            for alias in [data.get('official_name')] + data.get('aliases', []):
                if alias:
                    nlu["ratio"][alias.lower()] = rid
        
        # ë¶„ì„ ê´€ì 
        for vid, data in self.config.get('financial_ratios', {}).get('viewpoints', {}).items():
            for alias in [data.get('name')] + data.get('aliases', []):
                if alias:
                    nlu["viewpoint"][alias.lower()] = vid
        
        # ì‹œê°„ ê´€ê³„
        for rel_type, aliases in self.config.get('context_classifiers', {}).get('temporal_classifiers', {}).get('relationship_aliases', {}).items():
            if isinstance(aliases, list):
                for alias in aliases:
                    if alias:
                        nlu["temporal_relation"][alias.lower()] = rel_type
        
        # ì‹œê°„ ë‹¨ìœ„
        for unit_id, aliases in self.config.get('context_classifiers', {}).get('temporal_classifiers', {}).get('unit_aliases', {}).items():
            if isinstance(aliases, list):
                for alias in aliases:
                    if alias:
                        nlu["temporal_unit"][alias.lower()] = unit_id
        
        # ë¶„ì„ íƒ€ì…
        for analysis_type, aliases in self.config.get('context_classifiers', {}).get('temporal_classifiers', {}).get('analysis_type_aliases', {}).items():
            if isinstance(aliases, list):
                for alias in aliases:
                    if alias:
                        nlu["analysis_type"][alias.lower()] = analysis_type
        
        # ë¹„êµ íƒ€ì… (ê³„íš-ì‹¤ì )
        plan_vs_actual = self.config.get('relationships', {}).get('contextual_relationships', {}).get('PLAN_VS_ACTUAL', {})
        if plan_vs_actual:
            for alias in plan_vs_actual.get('aliases', []):
                if alias:
                    nlu["comparison_type"][alias.lower()] = "PLAN_VS_ACTUAL"
        
        return nlu
    
    def _create_system_prompt(self):
        """GDBì˜ ì§€ëŠ¥ì„ 100% í™œìš©í•˜ëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""
        return """You are 'GMIS Agent v4', a financial expert navigating a powerful Knowledge Graph (v5).

**Core Principle: ASK THE GRAPH. DO NOT ASSUME.**

**ğŸ¯ Primary Decision Flow (MANDATORY FIRST STEP!):**

Before doing ANYTHING else, classify the user's request:

1. **Follow-up Action?** (í›„ì† ì‘ì—…)
   - Keywords: "ê·¸ë˜í”„", "ì°¨íŠ¸ë¡œ", "ì‹œê°í™”", "CSVë¡œ", "íŒŒì¼ë¡œ", "ì €ì¥", "ë‹¤ìš´ë¡œë“œ"
   - Check: Does `last_query_result` exist from previous turn?
   - **If YES**:
     * DO NOT run new query!
     * Call data_visualization or generate_downloadable_link immediately
     * Use cached data (omit `data` parameter)
     * After tool success: Simple confirmation only ("ì°¨íŠ¸ ìƒì„± ì™„ë£Œ. ê²½ë¡œ: ...")
     * **NO 4-part report!**

2. **New Data Query?** (ìƒˆ ë°ì´í„° ì¡°íšŒ)
   - Keywords: company names, account names, time periods
   - NOT a follow-up action
   - **If YES**: run_cypher_query â†’ pre-process â†’ 4-part report

3. **Knowledge Question?** (ì§€ì‹ ì§ˆë¬¸)
   - Keywords: "ë­ì•¼?", "ì˜ë¯¸ëŠ”?", "ì™œ?", "ì°¨ì´ëŠ”?"
   - **If YES**: general_knowledge_qa â†’ natural explanation

The Knowledge Graph contains ALL business logic, relationships, and calculation rules.
Your job is to translate user questions into graph traversals, NOT to memorize rules.

**ğŸ’¡ How to Leverage the Graph's Intelligence:**

1. **Time Aggregations:** Use the time hierarchy!
   - **Monthly data:** Use Period nodes directly
   - **Quarterly data:** Use `(p:Period)-[:PART_OF]->(q:Quarter)` and GROUP BY q.id
   - **Half-year data:** Use `(p:Period)-[:PART_OF]->(q:Quarter)-[:PART_OF]->(h:HalfYear)`
   - **Annual data:** Aggregate all months in the year
   
   Keywords to detect:
   - "ë¶„ê¸°ë³„", "1ë¶„ê¸°", "2ë¶„ê¸°", "Q1", "Q2" â†’ Use Quarter nodes
   - "ìƒë°˜ê¸°", "í•˜ë°˜ê¸°", "H1", "H2" â†’ Use HalfYear nodes
   - "ì›”ë³„", "ë§¤ì›”" â†’ Use Period nodes (default)

2. **Time Comparisons:** Use pre-built relationships
   - YoY: `MATCH (p1:Period)-[:PRIOR_YEAR_EQUIV]->(p2:Period)`
   - MoM: `MATCH (p1:Period)-[:PREVIOUS]->(p2:Period)`

3. **Formula Discovery:** Ask the graph for calculation structure
   - `MATCH (parent:Metric)-[r:SUM_OF]->(child:Metric) RETURN r.operation, child`

4. **Aggregation Rules:** Get from Account.aggregation property
   - `MATCH (a:Account {id: 'XXX'}) RETURN a.aggregation` â†’ 'SUM' or 'LAST'

5. **Two Data Levels:**
   - CORPORATE: `(c:Company)-[:HAS_STATEMENT]->(fs:FinancialStatement)`
   - SEGMENT: `(c:Company)-[:HAS_ALL_SEGMENTS]->(bs:BusinessSegment)`

**ğŸ’ GENEROUS ANSWER STRATEGY (ë°ì´í„° ì¡°íšŒ ì§ˆë¬¸ë§Œ!):**

**ONLY for DATA QUERIES** (run_cypher_query ì‚¬ìš© ì‹œ):

### 1. ìš”ì•½ (Executive Summary)
- Direct answer with actual numbers
- **CRITICAL**: If data includes MULTIPLE YEARS, you MUST mention ALL years!
  Example: "2022ë…„ì€ Xì›, 2023ë…„ì€ Yì›ìœ¼ë¡œ Z% ì¦ê°€í–ˆìŠµë‹ˆë‹¤"
- **CRITICAL**: You MUST specify the financial scope ('ì—°ê²°' or 'ë³„ë„') from `statement_scope` column!
  Example: "LS MnM(ì—°ê²°)ì˜ 2023ë…„ ì—°ê°„ ë§¤ì¶œì•¡ì€..."

### 2. ì§‘ê³„ ë°ì´í„° (Aggregated Table)
- Markdown table format
- Include all metrics AND all years in the data
- **For multi-year comparisons**: Create columns for each year
  Example: `| íšŒì‚¬ | 2022ë…„ | 2023ë…„ | ì¦ê°ë¥  |`
- If all data is from the same scope, mention it in title: `| ì§€í‘œ (ì—°ê²° ê¸°ì¤€) |`

### 3. ì›”ë³„ ìƒì„¸ (Monthly Evidence)
- ALWAYS show monthly breakdown
- This proves the summary
- **Format Guidelines:**
  * Single company: Vertical table (current format) âœ…
  * Multiple companies: **PIVOT table** (companies as columns for easy comparison)
    | ì›” | íšŒì‚¬A | íšŒì‚¬B | íšŒì‚¬C |
    |:---|---:|---:|---:|
  * Keep table concise (max 15-20 rows)

### 4. ì¸ì‚¬ì´íŠ¸ (Brief Insights)
- 2-3 sentences of analysis

**NEVER skip sections 2 and 3! Users need to see the evidence!**

**ğŸ”¢ Number Format Guidelines:**
- **ìš”ì•½**: ì¡°/ì–µ í˜¼ìš© (ì˜ˆ: "6ì¡° 2,171ì–µì›")
- **í…Œì´ë¸”**: 
  * 1ì¡° ì´ìƒ: "6.2ì¡°ì›" or "6ì¡° 2,171ì–µ"
  * 1ì¡° ë¯¸ë§Œ: "5,001ì–µì›" (ì–µ ë‹¨ìœ„)
- **ì¼ê´€ì„±**: ê°™ì€ í…Œì´ë¸” ë‚´ì—ì„œëŠ” ë™ì¼ ë‹¨ìœ„ ì‚¬ìš©!

**For KNOWLEDGE QUESTIONS** (general_knowledge_qa ì‚¬ìš© ì‹œ):
- Simple, clear explanation
- 3-5 paragraphs in natural Korean
- NO need for tables or structured format
- Just answer naturally and helpfully

**Example of CORRECT Answer Format:**

**Single Company:**
```
### 1. ìš”ì•½
LSì „ì„ (ì—°ê²°)ì˜ 2023ë…„ ì—°ê°„ ë§¤ì¶œì•¡ì€ **6ì¡° 2,171ì–µì›**, ì˜ì—…ì´ìµì€ **2,325ì–µì›**ì…ë‹ˆë‹¤.

### 2. ì§‘ê³„ ë°ì´í„°
| ì§€í‘œ (2023ë…„) | ê°’ |
|:---|:---|
| ë§¤ì¶œì•¡ | 6.2ì¡°ì› |
| ì˜ì—…ì´ìµ | 2,325ì–µì› |
| ì˜ì—…ì´ìµë¥  | 3.74% |

### 3. ì›”ë³„ ìƒì„¸
| ì›” | ë§¤ì¶œì•¡ (ì–µì›) | ì˜ì—…ì´ìµ (ì–µì›) |
|:---|---:|---:|
| 1ì›” | 5,001 | 93 |
| 2ì›” | 5,123 | 148 |
...
| 12ì›” | 5,890 | 267 |

### 4. ì¸ì‚¬ì´íŠ¸
í•˜ë°˜ê¸°ë¡œ ê°ˆìˆ˜ë¡ ë§¤ì¶œê³¼ ì´ìµì´ ì¦ê°€í•˜ëŠ” ì¶”ì„¸ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.
```

**Multiple Companies (PIVOT format):**
```
### 1. ìš”ì•½
2023ë…„ ì œì¡°4ì‚¬ ì¤‘ ë§¤ì¶œì•¡ 1ìœ„ëŠ” MnM (10.2ì¡°ì›), ì˜ì—…ì´ìµ 1ìœ„ëŠ” ELECTRIC (3,120ì–µì›)ì…ë‹ˆë‹¤.

### 2. ì§‘ê³„ ë°ì´í„°  
| íšŒì‚¬ | ë§¤ì¶œì•¡ | ì˜ì—…ì´ìµ | ì˜ì—…ì´ìµë¥  |
|:---|---:|---:|---:|
| MnM | 10.2ì¡° | 2,212ì–µ | 2.18% |
| ì „ì„  | 6.2ì¡° | 2,326ì–µ | 3.74% |
| ELECTRIC | 3.7ì¡° | 3,120ì–µ | 8.51% |

### 3. ì›”ë³„ ë¹„êµ (PIVOT)
| ì›” | ELECTRIC | MnM | ì „ì„  |
|:---|---:|---:|---:|
| 1ì›” | 264 | 353 | 126 |
| 2ì›” | 275 | -421 | 260 |
...
| ìƒë°˜ê¸° ê³„ | 1,772 | 818 | 976 |
| í•˜ë°˜ê¸° ê³„ | 1,347 | 1,400 | 1,340 |

### 4. ì¸ì‚¬ì´íŠ¸
MnMê³¼ ì „ì„ ì€ ìƒë°˜ê¸° ëŒ€ë¹„ í•˜ë°˜ê¸° ì¦ê°€, ELECTRICì€ ê°ì†Œ.
```


**Query Pattern Templates:**

**CORPORATE Level (ì „ì‚¬ ë ˆë²¨):**

ë‹¨ì¼ íšŒì‚¬ ì›”ë³„ ì¡°íšŒ:
```cypher
MATCH (c:Company {id: 'ELECTRIC'})-[:HAS_STATEMENT]->(fs:FinancialStatement)
WHERE fs.id CONTAINS '2023' AND fs.id CONTAINS 'ACTUAL'
MATCH (fs)-[:HAS_SCOPE]->(scope:StatementScope {id: 'CONSOLIDATED'})
MATCH (fs)-[:FOR_PERIOD]->(p:Period)
MATCH (fs)-[:CONTAINS]->(m:Metric)-[:INSTANCE_OF_RULE]->(a:Account)
WHERE a.id IN ['ë§¤ì¶œì•¡_í•©ê³„', 'ì˜ì—…ì´ìµ']
MATCH (m)-[:HAS_OBSERVATION]->(v:ValueObservation)
RETURN c.name, p.year, p.month, a.name, v.value, scope.id AS statement_scope
ORDER BY p.month
```

**ë¶„ê¸°ë³„ ì¡°íšŒ** (Use time hierarchy!):
```cypher
MATCH (c:Company {id: 'LSCNS_C'})-[:HAS_STATEMENT]->(fs:FinancialStatement)
WHERE fs.id CONTAINS '2023' AND fs.id CONTAINS 'ACTUAL'
MATCH (fs)-[:HAS_SCOPE]->(scope:StatementScope {id: 'CONSOLIDATED'})
MATCH (fs)-[:FOR_PERIOD]->(p:Period)-[:PART_OF]->(q:Quarter)
WHERE q.id IN ['2023-Q1', '2023-Q2', '2023-Q3', '2023-Q4']
MATCH (fs)-[:CONTAINS]->(m:Metric)-[:INSTANCE_OF_RULE]->(a:Account)
WHERE a.id IN ['ë§¤ì¶œì•¡_í•©ê³„', 'ì˜ì—…ì´ìµë¥ ']
MATCH (m)-[:HAS_OBSERVATION]->(v:ValueObservation)
RETURN c.name, q.id as quarter, a.name, sum(v.value) as quarterly_value
ORDER BY q.id, a.name
```

**ê³„íš-ì‹¤ì  ë¹„êµ ì¡°íšŒ** (PLAN vs ACTUAL):
```cypher
// When user asks "ê³„íš ëŒ€ë¹„", "ì‹¤ì  ëŒ€ë¹„", "ëª©í‘œ ë‹¬ì„±ë¥ ", "ë‹¬ì„±ë¥ "
MATCH (c:Company {id: 'ELECTRIC'})-[:HAS_STATEMENT]->(fs_actual:FinancialStatement)
WHERE fs_actual.id CONTAINS '2023' AND fs_actual.id CONTAINS 'ACTUAL'
MATCH (fs_actual)-[:COMPARISON_FOR]->(fs_plan:FinancialStatement)
MATCH (fs_actual)-[:FOR_PERIOD]->(p:Period)
MATCH (fs_actual)-[:CONTAINS]->(m_actual:Metric)-[:INSTANCE_OF_RULE]->(a:Account)
WHERE a.id = 'ë§¤ì¶œì•¡_í•©ê³„'
MATCH (fs_plan)-[:CONTAINS]->(m_plan:Metric)-[:INSTANCE_OF_RULE]->(a)
MATCH (m_actual)-[:HAS_OBSERVATION]->(v_actual:ValueObservation)
MATCH (m_plan)-[:HAS_OBSERVATION]->(v_plan:ValueObservation)
RETURN 
  c.name, 
  p.month, 
  a.name,
  v_plan.value as plan,
  v_actual.value as actual,
  ((v_actual.value - v_plan.value) / v_plan.value * 100) as variance_pct
ORDER BY p.month
```

**YTD (Year-to-Date) ëˆ„ê³„ ì¡°íšŒ**:
```cypher
// When user asks "ëˆ„ê³„", "ì—°ì´ˆë¶€í„°", "YTD", "~ì›”ê¹Œì§€"
// Single optimized query - finds latest month automatically
MATCH (c:Company {id: 'MnM'})-[:HAS_STATEMENT]->(fs:FinancialStatement)
WHERE fs.id CONTAINS '2023' AND fs.id CONTAINS 'ACTUAL'
MATCH (fs)-[:FOR_PERIOD]->(p:Period)
MATCH (fs)-[:CONTAINS]->(m:Metric)-[:INSTANCE_OF_RULE]->(a:Account)
WHERE a.id = 'ë§¤ì¶œì•¡_í•©ê³„'
MATCH (m)-[:HAS_OBSERVATION]->(v:ValueObservation)
WITH c, a, max(p.month) as latest_month, collect({month: p.month, value: v.value}) as monthly_data
UNWIND monthly_data as md
RETURN c.name, a.name, sum(md.value) as ytd_total, latest_month

// If user specifies month: "9ì›”ê¹Œì§€ ëˆ„ê³„"
// Add: WHERE p.month <= 9 after MATCH (fs)-[:FOR_PERIOD]->(p:Period)
```

**CRITICAL**: 
- For quarterly data: Use Quarter nodes and aggregate with `sum(v.value)`
- Quarter IDs: '2023-Q1', '2023-Q2', '2023-Q3', '2023-Q4'
- For PLAN vs ACTUAL: Use COMPARISON_FOR relationship
- For YTD: Use WITH clause to find max month and aggregate in single query
- Calculate variance_pct in Cypher for efficiency
- Keywords: 
  * PLAN_VS_ACTUAL: "ê³„íš ëŒ€ë¹„", "ì‹¤ì  ëŒ€ë¹„", "ëª©í‘œ ë‹¬ì„±ë¥ ", "ë‹¬ì„±ë¥ ", "ì˜ˆì‚° ëŒ€ë¹„"
  * YTD: "ëˆ„ê³„", "ëˆ„ì ", "ì—°ì´ˆë¶€í„°", "YTD", "~ê¹Œì§€"
- ALWAYS include `scope.id AS statement_scope` in RETURN!


ë‹¤ì¤‘ íšŒì‚¬ ë¹„êµ (íŒ¨í„´ - NLU ì»¨í…ìŠ¤íŠ¸ í™œìš©):
```cypher
// STEP 1: Get Company/Account IDs from NLU context
//   Example: User asks "ì „ì„ ê³¼ MnMì˜ ë§¤ì¶œê³¼ ì˜ì—…ì´ìµ"
//   NLU provides: 'ì „ì„ ' â†’ 'LSCNS_C', 'MnM' â†’ 'MnM'
//   Accounts: 'ë§¤ì¶œ' â†’ 'ë§¤ì¶œì•¡_í•©ê³„', 'ì˜ì—…ì´ìµ' â†’ 'ì˜ì—…ì´ìµ'
//   Special Rule: MnM â†’ use 'ì¡°ì •ì˜ì—…ì´ìµ' instead

MATCH (c:Company)-[:HAS_STATEMENT]->(fs:FinancialStatement)
WHERE c.id IN [/* company_ids_from_nlu */]
  AND fs.id CONTAINS '2023' AND fs.id CONTAINS 'ACTUAL'
MATCH (fs)-[:HAS_SCOPE]->(scope:StatementScope {id: 'CONSOLIDATED'})
MATCH (fs)-[:FOR_PERIOD]->(p:Period)
MATCH (fs)-[:CONTAINS]->(m:Metric)-[:INSTANCE_OF_RULE]->(a:Account)
WHERE (c.id = /* company_1 */ AND a.id IN [/* account_ids_for_company_1 */])
   OR (c.id = /* company_2 */ AND a.id IN [/* account_ids_for_company_2_with_special_rules */])
MATCH (m)-[:HAS_OBSERVATION]->(v:ValueObservation)
RETURN c.name, p.year, p.month, a.name, v.value, scope.id AS statement_scope
ORDER BY c.name, p.month, a.name
```
**CRITICAL**: Include `scope.id AS statement_scope` in RETURN!
â†’ Use NLU context and special rules to construct WHERE clauses!
```

**SEGMENT Level Patterns:**

**Pattern A: ì‚¬ì—… ëª©ë¡ ì¡°íšŒ ("ì–´ë–¤ ì‚¬ì—…ì´ ìˆì–´?", "ì‚¬ì—… í•­ëª©ì€?")**

ê¸°ë³¸ ëª©ë¡ (ëª¨ë“  ì‚¬ì—… í¬í•¨):
```cypher
MATCH (c:Company {id: 'ELECTRIC'})-[:HAS_ALL_SEGMENTS]->(bs:BusinessSegment)
RETURN DISTINCT bs.name
ORDER BY bs.name
```

CICë³„ ê·¸ë£¹í™” ("CICë³„ë¡œ", "ë¶€ë¬¸ë³„ë¡œ", "ì¡°ì§ë³„ë¡œ"):
```cypher
MATCH (company:Company {id: 'ELECTRIC'})
// ë³¸ì‚¬ ì§ì† ì‚¬ì—… (CIC ì•„ë‹Œ ê²ƒ)
OPTIONAL MATCH (company)<-[:PART_OF]-(bs_direct:BusinessSegment)
WHERE NOT (bs_direct)<-[:PART_OF]-(:CIC)
// ì „ë ¥CIC ì†Œì† ì‚¬ì—…
OPTIONAL MATCH (company)<-[:PART_OF]-(cic_power:CIC {id: 'ì „ë ¥CIC'})<-[:PART_OF]-(bs_power:BusinessSegment)
// ìë™í™”CIC ì†Œì† ì‚¬ì—…
OPTIONAL MATCH (company)<-[:PART_OF]-(cic_auto:CIC {id: 'ìë™í™”CIC'})<-[:PART_OF]-(bs_auto:BusinessSegment)

// ê²°ê³¼ ì¡°í•©
WITH 
  collect(DISTINCT bs_direct.name) AS ë³¸ì‚¬ì§ì†,
  collect(DISTINCT bs_power.name) AS ì „ë ¥CIC,
  collect(DISTINCT bs_auto.name) AS ìë™í™”CIC

RETURN 
  'ë³¸ì‚¬ì§ì†' AS ì†Œì†, ë³¸ì‚¬ì§ì† AS ì‚¬ì—…ëª©ë¡
UNION
RETURN 
  'ì „ë ¥CIC' AS ì†Œì†, ì „ë ¥CIC AS ì‚¬ì—…ëª©ë¡  
UNION
RETURN
  'ìë™í™”CIC' AS ì†Œì†, ìë™í™”CIC AS ì‚¬ì—…ëª©ë¡
```

ê°„ë‹¨ ë²„ì „ (CICë³„ë§Œ):
```cypher
MATCH (cic:CIC)<-[:PART_OF]-(bs:BusinessSegment)
WHERE cic.id IN ['ì „ë ¥CIC', 'ìë™í™”CIC']
RETURN cic.name AS ì†Œì†, collect(bs.name) AS ì‚¬ì—…ëª©ë¡
ORDER BY cic.name
```

**Pattern B: ì‚¬ì—…ë³„ ì†ìµ ì¡°íšŒ ("ì‚¬ì—…ë³„ ë§¤ì¶œì€?", "ë¶€ìŠ¤ë‹¥íŠ¸ì˜ ë§¤ì¶œì€?")**

íŠ¹ì • ì‚¬ì—… ì•„ì´í…œ ìƒì„¸:
```cypher
MATCH (bs:BusinessSegment {{name: 'ë¶€ìŠ¤ë‹¥íŠ¸'}})<-[:FOR_SEGMENT]-(m:Metric)
MATCH (m)-[:INSTANCE_OF_RULE]->(a:Account)
MATCH (m)-[:HAS_OBSERVATION]->(v:ValueObservation)
WHERE v.region = 'ì „ì²´' AND v.value IS NOT NULL
MATCH (m)-[:CONTAINS]-(fs:FinancialStatement)-[:FOR_PERIOD]->(p:Period)
WHERE fs.id CONTAINS '2023' AND fs.id CONTAINS 'ACTUAL'
RETURN bs.name, p.year, p.month, a.name, v.value
ORDER BY p.month, a.name
```

ëª¨ë“  ì‚¬ì—… ì•„ì´í…œ ë¹„êµ:
```cypher
MATCH (c:Company {{id: 'ELECTRIC'}})-[:HAS_ALL_SEGMENTS]->(bs:BusinessSegment)
MATCH (m:Metric)-[:FOR_SEGMENT]->(bs)
MATCH (m)-[:INSTANCE_OF_RULE]->(a:Account)
WHERE a.name = 'ë§¤ì¶œì•¡'  // SEGMENT data uses short names!
MATCH (m)-[:HAS_OBSERVATION]->(v:ValueObservation)
WHERE v.region = 'ì „ì²´' AND v.value IS NOT NULL
MATCH (m)-[:CONTAINS]-(fs:FinancialStatement)
WHERE fs.id CONTAINS '2023' AND fs.id CONTAINS 'ACTUAL'
RETURN bs.name, sum(v.value) AS total_revenue
ORDER BY total_revenue DESC
```

**CRITICAL for SEGMENT Accounts:**
ì‚¬ì—…ë³„ ë°ì´í„°ì˜ AccountëŠ” Term ë…¸ë“œë¥¼ í†µí•´ ì°¾ìœ¼ì„¸ìš”:

Step 1: Termìœ¼ë¡œ Account ì°¾ê¸°
```cypher
MATCH (t:Term {{value: 'ë§¤ì¶œì•¡'}})<-[:ALSO_KNOWN_AS]-(a:Account)
RETURN a.id
```
â†’ 'ë§¤ì¶œì•¡_í•©ê³„'

Step 2: ì‚¬ì—…ë³„ ë°ì´í„° ì¡°íšŒì— ì‚¬ìš©
```cypher
MATCH (bs:BusinessSegment {{name: 'ë¶€ìŠ¤ë‹¥íŠ¸'}})<-[:FOR_SEGMENT]-(m)
MATCH (m)-[:INSTANCE_OF_RULE]->(a:Account)
// Termìœ¼ë¡œ ì°¾ì€ Account ì‚¬ìš©
MATCH (t:Term)<-[:ALSO_KNOWN_AS]-(a)
WHERE t.value IN ['ë§¤ì¶œì•¡', 'ì˜ì—…ì´ìµ', 'ì„¸ì „ì´ìµ']
...
```

**Critical for SEGMENT Accounts:**
To find the correct Account.id for segment data queries, use these methods in order:

1. **Use Term Node (BEST):** Query the graph to find Account linked to Term.
   `MATCH (t:Term {value: 'ë§¤ì¶œì•¡'})<-[:ALSO_KNOWN_AS]-(a:Account) RETURN a.id`

2. **Use Dynamic Context:** If Term fails, refer to 'Segment Account Mapping' in runtime context.

**ìš©ì–´**: "ì‚¬ì—… ì•„ì´í…œ" or "ì‚¬ì—… í•­ëª©" (NOT "ì‚¬ì—… ë¶€ë¬¸"!)
```

**ğŸš¨ CRITICAL: Group Queries with Special Rules ğŸš¨**

When a user asks for data from a company group (e.g., "ì œì¡°4ì‚¬") AND some companies have special handling rules:

**YOU MUST use this exact pattern to avoid omitting companies:**

Step 1: Mentally divide the group into two parts:
- **Normal Group:** Companies that use standard accounts
- **Exception Group:** Companies with special rules (e.g., MnM uses 'ì¡°ì •ì˜ì—…ì´ìµ')

Step 2: Construct WHERE clause with EXPLICIT OR logic:

```cypher
WHERE
  -- Normal companies (list ALL of them explicitly!)
  ( c.id IN ['LSCNS_C', 'ELECTRIC', 'ì— íŠ¸ë¡ '] AND a.id IN ['ë§¤ì¶œì•¡_í•©ê³„', 'ì˜ì—…ì´ìµ', 'ë‹¹ê¸°ìˆœì´ìµ'] )
  OR
  -- Exception companies (handle separately)
  ( c.id = 'MnM' AND a.id IN ['ë§¤ì¶œì•¡_í•©ê³„', 'ì¡°ì •ì˜ì—…ì´ìµ', 'ë‹¹ê¸°ìˆœì´ìµ'] )
```

**âš ï¸ CRITICAL:** When you create the "Normal Group" list, you MUST include ALL companies that are NOT in the exception group. Do NOT accidentally omit any company!

**ğŸ¢ Company Groups:**
When a user mentions a group name (e.g., "ì œì¡°4ì‚¬"), refer to the **'Company Groups' mapping** 
provided in the dynamic context at runtime. The context will give you the exact list of company IDs.
DO NOT guess the members!

**CRITICAL: How to use Company Groups in queries:**
1. Look at the runtime context's "Company Groups" section
2. Find the group name (e.g., "ì œì¡°4ì‚¬")
3. Extract ALL company IDs from that group
4. Use ALL of them in your WHERE clause

Example for "ì œì¡°4ì‚¬" (from runtime context):
- "ì œì¡°4ì‚¬": ["ELECTRIC (LS ELECTRIC)", "LSCNS_C (LSì „ì„ (ì—°ê²°))", "MnM (LS MnM)", "ì— íŠ¸ë¡  (LSì— íŠ¸ë¡ )"]
- Extract IDs: ELECTRIC, LSCNS_C, MnM, ì— íŠ¸ë¡ 
- Query: WHERE c.id IN ['ELECTRIC', 'LSCNS_C', 'MnM', 'ì— íŠ¸ë¡ ']
- You MUST include ALL 4 companies!

**CRITICAL for SEGMENT:**
- BusinessSegment has NO [:HAS_STATEMENT] relationship!
- Use [:FOR_SEGMENT] from Metric
- For data queries: MUST filter v.region = 'ì „ì²´' AND v.value IS NOT NULL
- For list queries: Just query BusinessSegment nodes directly
```

**Critical Notes:**
- Get monthly data first, then aggregate yourself
- CORPORATE data has NO v.region property!
- SEGMENT data REQUIRES v.region = 'ì „ì²´' filter
- Account.id: Korean names ('ë§¤ì¶œì•¡_í•©ê³„', 'ì˜ì—…ì´ìµ')

**ğŸš¨ Data Availability:**
- CORPORATE data (ì „ì‚¬ ë ˆë²¨): 2022, 2023, 2024
- SEGMENT data (ì‚¬ì—…ë³„): **2024ë…„ë§Œ ì‚¬ìš© ê°€ëŠ¥**
- If SEGMENT query returns 0 records for 2023: Suggest "2024ë…„ ë°ì´í„°ë¥¼ ì¡°íšŒí•´ë³´ì‹œê² ìŠµë‹ˆê¹Œ?"

**Tools:**
- run_cypher_query(query: str) - LS Group ë°ì´í„° ì¡°íšŒ
- data_visualization(chart_type, title, x_col='p.month', y_cols=['v.value'], company_filter=None, account_filter=None, year_filter=None, show_trendline=False) - ì°¨íŠ¸ ìƒì„±
  * data parameterëŠ” ìƒëµ (ìë™ìœ¼ë¡œ ìºì‹œëœ ë°ì´í„° ì‚¬ìš©)
  * company_filter: íšŒì‚¬ëª… í•„í„° (ì˜ˆ: "ì „ì„ ", "ELECTRIC")
  * account_filter: ê³„ì •ëª… í•„í„° (ì˜ˆ: "ë§¤ì¶œ", "ì˜ì—…ì´ìµ")
  * year_filter: ì—°ë„ í•„í„° (ì˜ˆ: 2022, 2023) - If user specifies year, use this!
  * show_trendline: Trueë©´ ì„ í˜• íšŒê·€ ì¶”ì„¸ì„  ì¶”ê°€ (line chart only)
- generate_downloadable_link(data, file_name, file_type) - CSV/JSON ì €ì¥
- calculate_financial_ratio(ratio_id, company_id, period='2023') - ì¬ë¬´ë¹„ìœ¨ ìë™ ê³„ì‚°
  * ratio_id: 'ROE', 'ë§¤ì¶œì±„ê¶ŒíšŒì „ìœ¨' ë“± (CALCULATED íƒ€ì…ë§Œ)
  * Returns calculated value with formula and components
- get_ratios_by_viewpoint(viewpoint_name) - ë¶„ì„ ê´€ì ë³„ ë¹„ìœ¨ ëª©ë¡
  * viewpoint_name: "ìˆ˜ìµì„±", "ì•ˆì •ì„±", "í™œë™ì„±", "ì„±ì¥ì„±"
  * Returns list of all ratios in that viewpoint
- get_definition(term) - ì¬ë¬´ ìš©ì–´ ì •ì˜ ì¡°íšŒ
  * term: "ì˜ì—…ì´ìµ", "ROE" ë“±
  * Returns definition from config.json (more accurate than general knowledge!)
  * Use this BEFORE general_knowledge_qa for term definitions
- general_knowledge_qa(question: str) - ì¬ë¬´/ê²½ì˜ ì§€ì‹ ì œê³µ
  * Use when get_definition doesn't find the term

**ğŸ¯ Two Types of Questions (ì¤‘ìš”!):**

A. **DATA QUERIES** (LS Group ë°ì´í„°):
   - "ì „ì„ ì˜ ë§¤ì¶œì€?" â†’ run_cypher_query
   - "3ë¶„ê¸° ì˜ì—…ì´ìµ" â†’ run_cypher_query
   - Use GDB for specific company data

B. **KNOWLEDGE QUESTIONS** (ì¬ë¬´ ì§€ì‹):
   - "ë¶€ì±„ë¹„ìœ¨ì´ ë­ì•¼?" â†’ general_knowledge_qa
   - "ì—°ê²°ê³¼ ë³„ë„ì˜ ì°¨ì´ëŠ”?" â†’ general_knowledge_qa
   - "ì™œ ë†’ì•„?" â†’ general_knowledge_qa  
   - "ì¼ë°˜ì ìœ¼ë¡œ ì¢‹ì€ ìˆ˜ì¤€ì€?" â†’ general_knowledge_qa
   - Use LLM's built-in knowledge

**You can FREELY SWITCH between data queries and knowledge provision!**

When to use general_knowledge_qa:
- Definitions (ì •ì˜)
- Explanations (ì„¤ëª…)
- "ì™œ?", "ì´ìœ ëŠ”?", "ì›ì¸ì€?" questions
- Industry standards or benchmarks
- General financial concepts

**ğŸ’¡ Default Behavior Clarification (MANDATORY!):**
At the end of your answer for DATA QUERIES, you MUST add a clarification note about defaults:

- **If query used 'ì¡°ì •ì˜ì—…ì´ìµ' (MnM, E1, ê¸€ë¡œë²Œ)**:
  Add: `ğŸ’¡ [íšŒì‚¬ëª…]ì€(ëŠ”) ì¡°ì •ì˜ì—…ì´ìµ ê¸°ì¤€ì…ë‹ˆë‹¤. ì¼ë°˜ ì˜ì—…ì´ìµì´ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”.`

- **If result is 'CONSOLIDATED' and user didn't specify 'ë³„ë„'**:
  Add: `ğŸ’¡ ì—°ê²° ì¬ë¬´ì œí‘œ ê¸°ì¤€ì…ë‹ˆë‹¤. ë³„ë„ ê¸°ì¤€ì´ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”.`

- **If both apply, combine them**:
  `ğŸ’¡ [íšŒì‚¬ëª…]ì€(ëŠ”) ì¡°ì •ì˜ì—…ì´ìµ ê¸°ì¤€ì´ë©°, ëª¨ë“  ë°ì´í„°ëŠ” ì—°ê²° ì¬ë¬´ì œí‘œ ê¸°ì¤€ì…ë‹ˆë‹¤.`

Example:
```
### 4. ì¸ì‚¬ì´íŠ¸
...í•˜ë°˜ê¸° ì¦ê°€ ì¶”ì„¸...

ğŸ’¡ LS MnMì€ ì¡°ì •ì˜ì—…ì´ìµ ê¸°ì¤€ì´ë©°, ëª¨ë“  ë°ì´í„°ëŠ” ì—°ê²° ì¬ë¬´ì œí‘œ ê¸°ì¤€ì…ë‹ˆë‹¤.
```

**ğŸ’¡ Using Previous Query Results (IMPORTANT!):**
When user asks "ê·¸ë˜í”„ë¡œ", "ì°¨íŠ¸ë¡œ", "ì‹œê°í™”" after a data query:
- Check chat_history for "[ì¿¼ë¦¬ ì‹¤í–‰ ì™„ë£Œ]" message
- If found: **Call data_visualization WITHOUT the data parameter**
- System will automatically use the cached data
- You only need to specify: chart_type, title, x_col, y_cols
- Example Tool Call:
  ```
  data_visualization(
    chart_type="line",
    title="LSì „ì„  2023ë…„ ì›”ë³„ ë§¤ì¶œ",
    x_col="p.month",
    y_cols=["v.value"]
  )
  ```
  (data parameter is optional - system fills it automatically!)
"""
    
    # === Tools (v3 ê¸°ëŠ¥ ìœ ì§€ + ê°œì„ ) ===
    
    def run_cypher_query(self, query: str) -> dict:
        """Neo4j Cypher ì¿¼ë¦¬ ì‹¤í–‰ (í™˜ê° ë°©ì§€ ê°•í™”)"""
        
        # ë””ë²„ê¹…: ì‹¤ì œ ì‹¤í–‰ë˜ëŠ” ì¿¼ë¦¬ ì¶œë ¥ (logging ì‚¬ìš© - stdout ìº¡ì²˜ì˜ ì˜í–¥ ì•ˆ ë°›ìŒ)
        logging.info("="*80)
        logging.info("Executing Cypher Query:")
        logging.info(query)
        logging.info("="*80)
        
        try:
            with self.driver.session() as session:
                result = session.run(query)
                data = [record.data() for record in result]
                
                # [ê¸´ê¸‰ ìˆ˜ì •] 0ê°œ ë ˆì½”ë“œ ì‹œ ëª…í™•í•œ ì‹¤íŒ¨ ì‘ë‹µ
                if len(data) == 0:
                    return {
                        "status": "no_data",
                        "data": [],
                        "message": "ì¿¼ë¦¬ëŠ” ì„±ê³µí–ˆìœ¼ë‚˜ ì¡°íšŒ ê²°ê³¼ê°€ 0ê±´ì…ë‹ˆë‹¤. í•´ë‹¹ ë°ì´í„°ê°€ Knowledge Graphì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                    }
                
                return {"status": "success", "data": data}
        except Exception as e:
            error_msg = str(e)
            error_type = type(e).__name__
            
            # ì¼ë°˜ì ì¸ ì˜¤ë¥˜ íŒ¨í„´ ë¶„ì„ ë° íŒíŠ¸ ì œê³µ
            hints = []
            if "c.name" in query or "company.name" in query:
                hints.append("Hint: Company ë…¸ë“œëŠ” 'c.id'ë¡œ ì¡°íšŒí•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆ: {id: 'ELECTRIC'}")
            if "WHERE" in query and "year" in query and "fs.year" in query:
                hints.append("Hint: FinancialStatementì—ëŠ” year ì†ì„±ì´ ì—†ìŠµë‹ˆë‹¤. fs.id CONTAINS '2023' ì‚¬ìš©")
            if "v.region" in query and "HAS_STATEMENT" in query:
                hints.append("Hint: CORPORATE ë ˆë²¨ ë°ì´í„°ì—ëŠ” v.region ì†ì„±ì´ ì—†ìŠµë‹ˆë‹¤. í•„í„° ì œê±° í•„ìš”")
            if "'Revenue'" in query or "'Sales'" in query:
                hints.append("Hint: Account IDëŠ” í•œê¸€ì…ë‹ˆë‹¤. 'ë§¤ì¶œì•¡_í•©ê³„', 'ì˜ì—…ì´ìµ' ë“± ì‚¬ìš©")
            
            return {
                "status": "error",
                "error": error_msg,
                "error_type": error_type,
                "hints": hints,
                "original_query": query
            }
    
    def data_visualization(self, data: list = None, chart_type: str = 'bar', title: str = '', x_col: str = '', y_cols: list = None, company_filter: str = None, account_filter: str = None, year_filter: int = None, show_trendline: bool = False, return_base64: bool = True) -> dict:
        """
        ì°¨íŠ¸ ìƒì„± ë° PNG ì €ì¥ (í•„í„°ë§ ê¸°ëŠ¥ ê°•í™”)
        - company_filter: íŠ¹ì • íšŒì‚¬ ë°ì´í„°ë§Œ í•„í„°ë§
        - account_filter: íŠ¹ì • ê³„ì • ë°ì´í„°ë§Œ í•„í„°ë§
        - year_filter: íŠ¹ì • ì—°ë„ ë°ì´í„°ë§Œ í•„í„°ë§ (ì˜ˆ: 2022, 2023)
        - return_base64: Trueë©´ base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë°˜í™˜ (APIìš©)
        """
        # Gemini Function Callì—ì„œ íƒ€ì… ë³€í™˜
        if y_cols and not isinstance(y_cols, list):
            y_cols = list(y_cols)

        # dataê°€ ì—†ìœ¼ë©´ last_query_result ì‚¬ìš© (í›„ì† ìš”ì²­ ì²˜ë¦¬)
        if not data and self.last_query_result:
            print("[íŒíŠ¸] ì§ì „ ì¡°íšŒ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì°¨íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
            data = self.last_query_result.get("data")
            if not x_col and self.last_query_result.get("columns"):
                cols = self.last_query_result["columns"]
                if 'p.month' in cols or 'month' in cols:
                    x_col = 'p.month' if 'p.month' in cols else 'month'
                if not y_cols and 'v.value' in cols:
                    y_cols = ['v.value']
        
        if not data:
            return {"error": "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}

        try:
            df = pd.DataFrame(data)
            print(f"[DEBUG] í•„í„°ë§ ì „ ë°ì´í„°: {len(df)}ê°œ ë ˆì½”ë“œ")

            # [í•µì‹¬ ìˆ˜ì • 1] í•„í„°ë§ ë¡œì§ ê°•í™” - (ì—°ê²°), (ë³„ë„) ì œê±°
            if company_filter:
                # LLMì´ ìƒì„±í•œ "(ì—°ê²°)" ë“± ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
                clean_company_filter = company_filter.split('(')[0].strip()
                # regex=Falseë¡œ íŠ¹ìˆ˜ë¬¸ì ì˜¤ë¥˜ ë°©ì§€ ë° ì •í™•í•œ ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­
                if 'c.name' in df.columns:
                    df = df[df['c.name'].str.contains(clean_company_filter, case=False, na=False, regex=False)]
                    print(f"[DEBUG] íšŒì‚¬ í•„í„°({clean_company_filter}) ì ìš© í›„: {len(df)}ê°œ ë ˆì½”ë“œ")

            if account_filter:
                # ê³„ì • ì´ë¦„ë„ ë§ˆì°¬ê°€ì§€ë¡œ ìœ ì—°í•˜ê²Œ í•„í„°ë§
                clean_account_filter = account_filter.split(' ')[0].strip()
                if 'a.name' in df.columns:
                    df = df[df['a.name'].str.contains(clean_account_filter, case=False, na=False, regex=False)]
                    print(f"[DEBUG] ê³„ì • í•„í„°({clean_account_filter}) ì ìš© í›„: {len(df)}ê°œ ë ˆì½”ë“œ")
            
            if year_filter:
                # ì—°ë„ í•„í„°ë§
                if 'p.year' in df.columns:
                    df = df[df['p.year'] == year_filter]
                    print(f"[DEBUG] ì—°ë„ í•„í„°({year_filter}) ì ìš© í›„: {len(df)}ê°œ ë ˆì½”ë“œ")
                    logging.info(f"ì—°ë„ í•„í„° ì ìš©: {year_filter}ë…„ë§Œ")

            print(f"[DEBUG] ìµœì¢… í•„í„°ë§ ì™„ë£Œ: {len(df)}ê°œ ë ˆì½”ë“œ")
            if df.empty:
                return {"error": "í•„í„°ë§ ê²°ê³¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. íšŒì‚¬ëª…ì´ë‚˜ ê³„ì •ëª…ì„ í™•ì¸í•´ì£¼ì„¸ìš”."}

            # [ê°œì„ 4] ì°¨íŠ¸ ìƒì„± ì „ ì»¬ëŸ¼ ê²€ì¦
            required_cols = [x_col] + (y_cols if y_cols and y_cols != ['v.value'] else [])
            missing_cols = [col for col in required_cols if col and col not in df.columns]
            if missing_cols:
                error_msg = f"ë°ì´í„°ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ëˆ„ë½: {missing_cols}"
                logging.error(error_msg)
                return {"error": error_msg}
            
            # ì „ë¬¸ì ì¸ ì°¨íŠ¸ ìŠ¤íƒ€ì¼ ì„¤ì • (í•œê¸€ í°íŠ¸ ì„¤ì • ì œê±° - ëª¨ë“  í…ìŠ¤íŠ¸ ì˜ë¬¸í™”)
            plt.rcParams['font.family'] = 'sans-serif'
            plt.rcParams['axes.unicode_minus'] = False
            
            fig, ax = plt.subplots(figsize=(14, 8), facecolor='white')
            # ë°°ê²½ìƒ‰ ì œê±° (ê¹”ë”í•œ í°ìƒ‰)
            ax.set_facecolor('white')
            
            # ê°’ì„ ì–µì› ë‹¨ìœ„ë¡œ ë³€í™˜ (ê°€ë…ì„± í–¥ìƒ)
            def convert_to_eok(value):
                """ê°’ì„ ì–µì› ë‹¨ìœ„ë¡œ ë³€í™˜"""
                return value / 100000000 if pd.notna(value) else 0
            
            # í•œê¸€-ì˜ë¬¸ ë³€í™˜ í•¨ìˆ˜
            def translate_to_english(text):
                """í•œê¸€ ì¬ë¬´ ìš©ì–´ë¥¼ ì˜ë¬¸ìœ¼ë¡œ ë³€í™˜"""
                translations = {
                    # íšŒì‚¬ëª…
                    'LSì „ì„ ': 'LS Cable',
                    'LSì¼ë ‰íŠ¸ë¦­': 'LS ELECTRIC',
                    'LS MnM': 'LS MnM',
                    'LSì— ì•¤ì— ': 'LS MnM',
                    # ì¬ë¬´ ê³„ì •
                    'ë§¤ì¶œì•¡ í•©ê³„': 'Total Revenue',
                    'ë§¤ì¶œì•¡': 'Revenue',
                    'ì˜ì—…ì´ìµ': 'Operating Profit',
                    'ì¡°ì •ì˜ì—…ì´ìµ': 'Adjusted OP',
                    'ë‹¹ê¸°ìˆœì´ìµ': 'Net Income',
                    'ìì‚°ì´ê³„': 'Total Assets',
                    'ë¶€ì±„ì´ê³„': 'Total Liabilities',
                    'ìê¸°ìë³¸': 'Equity',
                    'ë§¤ì¶œì´ì´ìµ': 'Gross Profit',
                    'ì„¸ì „ì´ìµ': 'Pre-tax Income',
                    # ì¼ë°˜ ìš©ì–´
                    'ì›”ë³„': 'Monthly',
                    'ë…„': ' ',
                    'ì˜': ' ',
                    'ì—°ê²°': 'Consolidated',
                    'ë³„ë„': 'Separate'
                }
                result = text
                for kr, en in translations.items():
                    result = result.replace(kr, en)
                # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
                import re
                result = re.sub(r'\s+', ' ', result).strip()
                return result
            
            # ì„¸ë ¨ëœ ìƒ‰ìƒ íŒ”ë ˆíŠ¸ (ì±„ë„ ì¡°ì •)
            colors = [
                '#4f46e5',  # Indigo
                '#ef4444',  # Red
                '#10b981',  # Emerald
                '#f59e0b',  # Amber
                '#8b5cf6',  # Violet
                '#06b6d4',  # Cyan
                '#ec4899',  # Pink
                '#14b8a6'   # Teal
            ]
            
            # [í•µì‹¬ ìˆ˜ì • 2] y_colsë¥¼ ë™ì ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì—¬ëŸ¬ ê³„ì • ê·¸ë¦¬ê¸° ì§€ì›
            if not y_cols or y_cols == ['v.value']:
                # y_colsê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìœ¼ë©´, í•„í„°ë§ëœ ë°ì´í„°ì˜ ëª¨ë“  ê³„ì •ì„ ê·¸ë¦¼
                if 'a.name' in df.columns and 'v.value' in df.columns:
                    unique_accounts = df['a.name'].unique()
                    for idx, account in enumerate(unique_accounts):
                        subset = df[df['a.name'] == account].copy()
                        subset['v.value_eok'] = subset['v.value'].apply(convert_to_eok)
                        color = colors[idx % len(colors)]
                        account_en = translate_to_english(account)
                        
                        if chart_type == 'line':
                            line = ax.plot(subset[x_col], subset['v.value_eok'], 
                                   marker='o', label=account_en, linewidth=1.8, 
                                   markersize=6, color=color, alpha=0.9)
                            # ë°ì´í„° í¬ì¸íŠ¸ ìœ„ì— ê°’ í‘œì‹œ (ë°˜íˆ¬ëª… ë°°ê²½)
                            for x, y in zip(subset[x_col], subset['v.value_eok']):
                                ax.annotate(f'{int(y):,}', 
                                          (x, y), 
                                          textcoords="offset points",
                                          xytext=(0, 8),
                                          ha='center',
                                          fontsize=8,
                                          color='#1f2937',
                                          fontweight='600',
                                          bbox=dict(boxstyle='round,pad=0.3', 
                                                   facecolor='white', 
                                                   edgecolor=color,
                                                   alpha=0.8,
                                                   linewidth=1))
                        elif chart_type == 'bar':
                            bars = ax.bar(subset[x_col], subset['v.value_eok'], 
                                  label=account_en, alpha=0.85, color=color, edgecolor='white', linewidth=1.2)
                            # ë°” ìœ„ì— ê°’ í‘œì‹œ (ë°˜íˆ¬ëª… ë°°ê²½)
                            for bar in bars:
                                height = bar.get_height()
                                ax.annotate(f'{int(height):,}',
                                          xy=(bar.get_x() + bar.get_width() / 2, height),
                                          xytext=(0, 5),
                                          textcoords="offset points",
                                          ha='center', 
                                          va='bottom',
                                          fontsize=8,
                                          color='#1f2937',
                                          fontweight='600',
                                          bbox=dict(boxstyle='round,pad=0.3', 
                                                   facecolor='white', 
                                                   edgecolor=color,
                                                   alpha=0.8,
                                                   linewidth=1))
                    if len(unique_accounts) > 1:
                        ax.legend(fontsize=11, frameon=True, shadow=True, fancybox=True)
                else:
                    # ê¸°ë³¸ ë‹¨ìˆœ ì°¨íŠ¸
                    df['v.value_eok'] = df['v.value'].apply(convert_to_eok)
                    if chart_type == 'line':
                        ax.plot(df[x_col], df['v.value_eok'], marker='o', 
                               linewidth=1.8, markersize=6, color=colors[0], alpha=0.9)
                        # ë°ì´í„° í¬ì¸íŠ¸ ìœ„ì— ê°’ í‘œì‹œ (ë°˜íˆ¬ëª… ë°°ê²½)
                        for x, y in zip(df[x_col], df['v.value_eok']):
                            ax.annotate(f'{int(y):,}', 
                                      (x, y), 
                                      textcoords="offset points",
                                      xytext=(0, 8),
                                      ha='center',
                                      fontsize=8,
                                      color='#1f2937',
                                      fontweight='600',
                                      bbox=dict(boxstyle='round,pad=0.3', 
                                               facecolor='white', 
                                               edgecolor=colors[0],
                                               alpha=0.8,
                                               linewidth=1))
                    elif chart_type == 'bar':
                        bars = ax.bar(df[x_col], df['v.value_eok'], 
                              alpha=0.85, color=colors[0], edgecolor='white', linewidth=1.2)
                        # ë°” ìœ„ì— ê°’ í‘œì‹œ (ë°˜íˆ¬ëª… ë°°ê²½)
                        for bar in bars:
                            height = bar.get_height()
                            ax.annotate(f'{int(height):,}',
                                      xy=(bar.get_x() + bar.get_width() / 2, height),
                                      xytext=(0, 5),
                                      textcoords="offset points",
                                      ha='center', 
                                      va='bottom',
                                      fontsize=8,
                                      color='#1f2937',
                                      fontweight='600',
                                      bbox=dict(boxstyle='round,pad=0.3', 
                                               facecolor='white', 
                                               edgecolor=colors[0],
                                               alpha=0.8,
                                               linewidth=1))
            else:
                # y_colsê°€ ëª…ì‹œì ìœ¼ë¡œ ì£¼ì–´ì§€ë©´ ê¸°ì¡´ ë°©ì‹ëŒ€ë¡œ ê·¸ë¦¼
                for idx, y_col in enumerate(y_cols):
                    color = colors[idx % len(colors)]
                    y_col_en = translate_to_english(y_col)
                    
                    if chart_type == 'line':
                        ax.plot(df[x_col], df[y_col], marker='o', label=y_col_en,
                               linewidth=1.8, markersize=6, color=color, alpha=0.9)
                        # ë°ì´í„° í¬ì¸íŠ¸ ìœ„ì— ê°’ í‘œì‹œ (ë°˜íˆ¬ëª… ë°°ê²½)
                        for x, y in zip(df[x_col], df[y_col]):
                            ax.annotate(f'{int(y):,}', 
                                      (x, y), 
                                      textcoords="offset points",
                                      xytext=(0, 8),
                                      ha='center',
                                      fontsize=8,
                                      color='#1f2937',
                                      fontweight='600',
                                      bbox=dict(boxstyle='round,pad=0.3', 
                                               facecolor='white', 
                                               edgecolor=color,
                                               alpha=0.8,
                                               linewidth=1))
                    elif chart_type == 'bar':
                        bars = ax.bar(df[x_col], df[y_col], label=y_col_en, 
                              alpha=0.85, color=color, edgecolor='white', linewidth=1.2)
                        # ë°” ìœ„ì— ê°’ í‘œì‹œ (ë°˜íˆ¬ëª… ë°°ê²½)
                        for bar in bars:
                            height = bar.get_height()
                            ax.annotate(f'{int(height):,}',
                                      xy=(bar.get_x() + bar.get_width() / 2, height),
                                      xytext=(0, 5),
                                      textcoords="offset points",
                                      ha='center', 
                                      va='bottom',
                                      fontsize=8,
                                      color='#1f2937',
                                      fontweight='600',
                                      bbox=dict(boxstyle='round,pad=0.3', 
                                               facecolor='white', 
                                               edgecolor=color,
                                               alpha=0.8,
                                               linewidth=1))
                if len(y_cols) > 1:
                    ax.legend(fontsize=11, frameon=True, shadow=True, fancybox=True)

            # ì°¨íŠ¸ ìŠ¤íƒ€ì¼ë§ (ëª¨ë“  í…ìŠ¤íŠ¸ ì˜ë¬¸í™”)
            title_en = translate_to_english(title).strip()
            if not title_en or title_en == title:
                title_en = 'Financial Data Chart'
            
            ax.set_title(title_en, fontsize=18, fontweight='bold', pad=20)
            ax.set_xlabel('Month' if x_col == 'p.month' else x_col, fontsize=13, fontweight='600')
            ax.set_ylabel('Amount (100M KRW)', fontsize=13, fontweight='600')
            
            # ê·¸ë¦¬ë“œ ì œê±° (ê¹”ë”í•œ ì°¨íŠ¸)
            ax.grid(False)
            
            # ì¶• ìŠ¤íƒ€ì¼ë§ (ë¯¸ë‹ˆë©€)
            ax.spines['top'].set_visible(False)
            ax.spines['right'].set_visible(False)
            ax.spines['left'].set_color('#dddddd')
            ax.spines['left'].set_linewidth(1.5)
            ax.spines['bottom'].set_color('#dddddd')
            ax.spines['bottom'].set_linewidth(1.5)
            
            # Yì¶• í¬ë§·íŒ… (ì²œ ë‹¨ìœ„ êµ¬ë¶„ ì‰¼í‘œ)
            from matplotlib.ticker import FuncFormatter
            def format_with_comma(x, p):
                return f'{int(x):,}'
            ax.yaxis.set_major_formatter(FuncFormatter(format_with_comma))
            
            # ì¶”ì„¸ì„  ì¶”ê°€ (ì„ í˜• íšŒê·€)
            if show_trendline and chart_type == 'line' and 'v.value' in df.columns:
                import numpy as np
                
                if not y_cols or y_cols == ['v.value']:
                    if 'a.name' in df.columns:
                        # ì—¬ëŸ¬ ê³„ì •ì´ ìˆëŠ” ê²½ìš° ê°ê° ì¶”ì„¸ì„ 
                        for idx, account in enumerate(df['a.name'].unique()):
                            subset = df[df['a.name'] == account].copy()
                            # v.value_eok ì¬ê³„ì‚°
                            subset['v.value_eok'] = subset['v.value'].apply(convert_to_eok)
                            x_vals = subset[x_col].values
                            y_vals = subset['v.value_eok'].values
                            
                            if len(x_vals) > 1:  # ìµœì†Œ 2ê°œ ì´ìƒì˜ í¬ì¸íŠ¸ í•„ìš”
                                # ì„ í˜• íšŒê·€
                                z = np.polyfit(x_vals, y_vals, 1)
                                p = np.poly1d(z)
                                
                                # ì¶”ì„¸ì„  ê·¸ë¦¬ê¸°
                                ax.plot(x_vals, p(x_vals), "--", 
                                       color=colors[idx % len(colors)], 
                                       linewidth=1.5, 
                                       alpha=0.6,
                                       label=f'{translate_to_english(account)} Trend')
                    else:
                        # ë‹¨ì¼ ë°ì´í„°
                        df_copy = df.copy()
                        df_copy['v.value_eok'] = df_copy['v.value'].apply(convert_to_eok)
                        x_vals = df_copy[x_col].values
                        y_vals = df_copy['v.value_eok'].values
                        
                        if len(x_vals) > 1:
                            z = np.polyfit(x_vals, y_vals, 1)
                            p = np.poly1d(z)
                            ax.plot(x_vals, p(x_vals), "--", 
                                   color=colors[0], 
                                   linewidth=1.5, 
                                   alpha=0.6,
                                   label='Trend')
                            ax.legend(fontsize=11, frameon=True, shadow=True, fancybox=True)
            
            plt.tight_layout()
            
            # [ê°œì„ 2] í†µí•© ê²½ë¡œ ì‚¬ìš©
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"chart_{timestamp}.png"
            filepath = os.path.join(self.output_dir, filename)
            
            plt.savefig(filepath, dpi=150, bbox_inches='tight')
            plt.close(fig)
            
            logging.info(f"ì°¨íŠ¸ ì €ì¥ ì™„ë£Œ: {filename}")
            
            result = {
                "status": "success",
                "file_path": os.path.abspath(filepath)
            }
            
            # API í˜¸ì¶œ ì‹œ base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ë„ í•¨ê»˜ ë°˜í™˜
            if return_base64:
                import base64
                with open(filepath, 'rb') as img_file:
                    img_base64 = base64.b64encode(img_file.read()).decode('utf-8')
                    result["image_base64"] = img_base64
                    logging.info("ì°¨íŠ¸ ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”© ì™„ë£Œ")
            
            return result
        except Exception as e:
            logging.error(f"ì°¨íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return {"error": str(e)}
    
    def generate_downloadable_link(self, data: list, file_name: str, file_type: str = 'csv') -> dict:
        """CSV/JSON íŒŒì¼ ì €ì¥ (v3 + ê°œì„ 2: í†µí•© ê²½ë¡œ)"""
        if not data:
            return {"error": "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}
        
        try:
            df = pd.DataFrame(data)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            if file_type == 'csv':
                filename = f"{file_name}_{timestamp}.csv"
                # [ê°œì„ 2] í†µí•© ê²½ë¡œ ì‚¬ìš©
                filepath = os.path.join(self.output_dir, filename)
                df.to_csv(filepath, index=False, encoding='utf-8-sig')
            elif file_type == 'json':
                filename = f"{file_name}_{timestamp}.json"
                filepath = os.path.join(self.output_dir, filename)
                df.to_json(filepath, orient='records', indent=2, force_ascii=False)
            else:
                return {"error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_type}"}
            
            logging.info(f"íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filename}")
            
            return {
                "status": "success",
                "file_path": os.path.abspath(filepath)
            }
        except Exception as e:
            logging.error(f"íŒŒì¼ ìƒì„± ì˜¤ë¥˜: {e}")
            return {"error": str(e)}
    
    def calculate_financial_ratio(self, ratio_id: str, company_id: str, period: str = '2023') -> dict:
        """
        config.jsonì˜ formulaë¥¼ ì½ê³  ì¬ë¬´ë¹„ìœ¨ ìë™ ê³„ì‚°
        
        Args:
            ratio_id: 'ROE', 'ë§¤ì¶œì±„ê¶ŒíšŒì „ìœ¨' ë“±
            company_id: 'ELECTRIC', 'MnM' ë“±
            period: '2023', '2024' ë“±
        
        Returns:
            {"status": "success", "ratio_name": "ROE", "value": 15.2, ...}
        """
        try:
            ratio_config = self.config['financial_ratios']['ratios'].get(ratio_id)
            
            if not ratio_config:
                return {"status": "error", "message": f"'{ratio_id}' ë¹„ìœ¨ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
            if ratio_config['type'] != 'CALCULATED':
                return {"status": "error", "message": f"'{ratio_id}'ëŠ” ì´ë¯¸ ì €ì¥ëœ ê°’ì…ë‹ˆë‹¤. ì§ì ‘ ì¡°íšŒí•˜ì„¸ìš”."}
            
            # 1. êµ¬ì„± ìš”ì†Œë³„ë¡œ aggregation íƒ€ì…ì— ë§ê²Œ ì¡°íšŒ
            components = ratio_config['components']
            component_values = {}
            
            for comp_account_id in components:
                account_config = self.config['entities']['accounts'].get(comp_account_id)
                if not account_config:
                    return {"status": "error", "message": f"êµ¬ì„± ìš”ì†Œ '{comp_account_id}'ì˜ ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
                
                agg_type = account_config.get('aggregation', 'SUM')
                
                # ì§‘ê³„ ìœ í˜•ì— ë”°ë¼ ë‹¤ë¥¸ ì¿¼ë¦¬ ìƒì„±
                if agg_type == 'SUM':
                    # IS í•­ëª©: ì „ì²´ ê¸°ê°„ í•©ê³„
                    query = f"""
                    MATCH (c:Company {{id: '{company_id}'}})-[:HAS_STATEMENT]->(fs:FinancialStatement)
                    WHERE fs.id CONTAINS '{period}' AND fs.id CONTAINS 'ACTUAL'
                    MATCH (fs)-[:HAS_SCOPE]->(scope:StatementScope {{id: 'CONSOLIDATED'}})
                    MATCH (fs)-[:CONTAINS]->(m:Metric)-[:INSTANCE_OF_RULE]->(a:Account {{id: '{comp_account_id}'}})
                    MATCH (m)-[:HAS_OBSERVATION]->(v:ValueObservation)
                    RETURN sum(v.value) as value
                    """
                elif agg_type == 'LAST':
                    # BS í•­ëª©: ë§ˆì§€ë§‰ ì›” ê°’
                    query = f"""
                    MATCH (c:Company {{id: '{company_id}'}})-[:HAS_STATEMENT]->(fs:FinancialStatement)
                    WHERE fs.id CONTAINS '{period}' AND fs.id CONTAINS 'ACTUAL'
                    MATCH (fs)-[:HAS_SCOPE]->(scope:StatementScope {{id: 'CONSOLIDATED'}})
                    MATCH (fs)-[:FOR_PERIOD]->(p:Period)
                    MATCH (fs)-[:CONTAINS]->(m:Metric)-[:INSTANCE_OF_RULE]->(a:Account {{id: '{comp_account_id}'}})
                    MATCH (m)-[:HAS_OBSERVATION]->(v:ValueObservation)
                    RETURN v.value as value
                    ORDER BY p.year DESC, p.month DESC
                    LIMIT 1
                    """
                else:
                    return {"status": "error", "message": f"'{comp_account_id}'ì˜ ì§‘ê³„ ìœ í˜• '{agg_type}'ì€ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."}
                
                # ì¿¼ë¦¬ ì‹¤í–‰
                result = self.run_cypher_query(query)
                
                if result['status'] == 'success' and result.get('data') and len(result['data']) > 0:
                    value = result['data'][0].get('value')
                    if value is not None:
                        component_values[comp_account_id] = value
                        logging.info(f"{comp_account_id} ({agg_type}): {value}")
                    else:
                        return {"status": "error", "message": f"'{comp_account_id}' ê°’ì´ nullì…ë‹ˆë‹¤."}
                else:
                    return {"status": "error", "message": f"'{comp_account_id}' ì¡°íšŒ ì‹¤íŒ¨"}
            
            if len(component_values) != len(components):
                return {"status": "error", "message": f"ì¼ë¶€ êµ¬ì„± ìš”ì†Œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í•„ìš”: {components}, ì¡°íšŒë¨: {list(component_values.keys())}"}
            
            # 2. ê³µì‹ íŒŒì‹± ë° ê³„ì‚°
            formula = ratio_config['formula_human']
            
            # ê³µì‹ì—ì„œ ê³„ì •ëª…ì„ ì‹¤ì œ ê°’ìœ¼ë¡œ ì¹˜í™˜
            expr = formula.replace(" ", "")  # ê³µë°± ì œê±°
            
            # ë””ë²„ê¹… ë¡œê·¸
            logging.info(f"ì›ë³¸ ê³µì‹: {formula}")
            logging.info(f"ê³µë°± ì œê±° í›„: {expr}")
            logging.info(f"Component values: {component_values}")
            
            # ê° êµ¬ì„± ìš”ì†Œë¥¼ ê°’ìœ¼ë¡œ ì¹˜í™˜
            # ëª¨ë“  ê°€ëŠ¥í•œ ì´ë¦„ì„ ìˆ˜ì§‘í•˜ê³  ê¸¸ì´ìˆœìœ¼ë¡œ ì •ë ¬ (ê¸´ ê²ƒë¶€í„° ì¹˜í™˜)
            substitutions = []
            
            for comp_id, value in component_values.items():
                account_config = self.config['entities']['accounts'].get(comp_id, {})
                possible_names = [
                    comp_id,
                    account_config.get('official_name', ''),
                ] + account_config.get('aliases', [])
                
                for name in possible_names:
                    if name:
                        name_no_space = name.replace(" ", "")
                        substitutions.append((name_no_space, str(value)))
            
            # ê¸¸ì´ìˆœ ì •ë ¬ (ê¸´ ê²ƒë¶€í„°) - ë¶€ë¶„ ë§¤ì¹­ ë¬¸ì œ ë°©ì§€
            substitutions.sort(key=lambda x: len(x[0]), reverse=True)
            
            # ì¹˜í™˜ ì‹¤í–‰
            for name_no_space, value in substitutions:
                if name_no_space in expr:
                    expr = expr.replace(name_no_space, value)
                    logging.info(f"ì¹˜í™˜ ì„±ê³µ: '{name_no_space}' -> '{value}'")
            
            logging.info(f"ìµœì¢… expression: {expr}")
            
            # ì•ˆì „í•œ eval ì‹¤í–‰
            try:
                import re
                # ìˆ«ì, ì†Œìˆ˜ì , ì—°ì‚°ì, ê´„í˜¸, ê³¼í•™ì  í‘œê¸°ë²•ë§Œ í—ˆìš©
                if not re.match(r'^[0-9eE\.\+\-\*\/\(\)]+$', expr):
                    logging.error(f"í—ˆìš©ë˜ì§€ ì•Šì€ ë¬¸ì í¬í•¨: {expr}")
                    return {"status": "error", "message": "ê³µì‹ì— í—ˆìš©ë˜ì§€ ì•Šì€ ë¬¸ì í¬í•¨", "expression": expr, "formula": formula}
                
                calculated_value = eval(expr)
                logging.info(f"ê³„ì‚° ê²°ê³¼: {calculated_value}")
                
            except Exception as e:
                logging.error(f"ê³„ì‚° ì‹¤íŒ¨: {e}")
                return {"status": "error", "message": f"ê³„ì‚° ì‹¤íŒ¨: {str(e)}", "expression": expr}
            
            return {
                "status": "success",
                "ratio_name": ratio_config['official_name'],
                "ratio_id": ratio_id,
                "value": round(calculated_value, 2),
                "unit": ratio_config.get('unit', ''),
                "formula": formula,
                "components": component_values,
                "period": period,
                "company": company_id
            }
            
        except Exception as e:
            logging.error(f"ì¬ë¬´ë¹„ìœ¨ ê³„ì‚° ì˜¤ë¥˜: {e}", exc_info=True)
            return {"status": "error", "message": str(e)}
    
    def get_ratios_by_viewpoint(self, viewpoint_name: str) -> dict:
        """
        íŠ¹ì • ë¶„ì„ ê´€ì ì˜ ëª¨ë“  ì¬ë¬´ë¹„ìœ¨ ë°˜í™˜
        
        Args:
            viewpoint_name: "ìˆ˜ìµì„±", "ì•ˆì •ì„±", "í™œë™ì„±", "ì„±ì¥ì„±"
        
        Returns:
            {"found": True, "viewpoint": "ìˆ˜ìµì„±", "ratios": [...]}
        """
        viewpoint_name_lower = viewpoint_name.lower()
        
        # 1. Viewpoint ID ì°¾ê¸°
        viewpoint_id = None
        viewpoint_official_name = None
        for vid, vdata in self.config['financial_ratios']['viewpoints'].items():
            all_names = [vdata['name']] + vdata.get('aliases', [])
            if any(viewpoint_name_lower == name.lower() for name in all_names):
                viewpoint_id = vid
                viewpoint_official_name = vdata['name']
                break
        
        if not viewpoint_id:
            return {"found": False, "message": f"'{viewpoint_name}' ê´€ì ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        
        # 2. í•´ë‹¹ viewpointì˜ ëª¨ë“  ratios ìˆ˜ì§‘
        ratios = []
        for rid, rdata in self.config['financial_ratios']['ratios'].items():
            if rdata.get('viewpoint') == viewpoint_id:
                ratios.append({
                    "id": rid,
                    "name": rdata['official_name'],
                    "type": rdata['type'],
                    "description": rdata.get('description'),
                    "unit": rdata.get('unit')
                })
        
        return {
            "found": True,
            "viewpoint": viewpoint_official_name,
            "viewpoint_id": viewpoint_id,
            "ratios": ratios,
            "count": len(ratios)
        }
    
    def get_definition(self, term: str) -> dict:
        """
        ì¬ë¬´ ìš©ì–´ì˜ ì •ì˜ë¥¼ config.jsonì—ì„œ ì¡°íšŒ
        
        Args:
            term: "ì˜ì—…ì´ìµ", "ROE", "ë¶€ì±„ë¹„ìœ¨" ë“±
        
        Returns:
            {"found": True, "type": "account", "definition": {...}}
        """
        term_lower = term.lower()
        
        # 1. Accounts ê²€ìƒ‰
        for aid, adata in self.config['entities']['accounts'].items():
            all_names = [adata['official_name']] + adata.get('aliases', [])
            if any(term_lower == name.lower() for name in all_names):
                return {
                    "found": True,
                    "type": "account",
                    "term": term,
                    "official_name": adata['official_name'],
                    "category": adata['category'],
                    "description": adata.get('description', 'ì„¤ëª… ì—†ìŒ'),
                    "aggregation": adata.get('aggregation'),
                    "id": aid
                }
        
        # 2. Financial Ratios ê²€ìƒ‰
        for rid, rdata in self.config['financial_ratios']['ratios'].items():
            all_names = [rdata['official_name']] + rdata.get('aliases', [])
            if any(term_lower == name.lower() for name in all_names):
                return {
                    "found": True,
                    "type": "ratio",
                    "term": term,
                    "official_name": rdata['official_name'],
                    "viewpoint": rdata['viewpoint'],
                    "description": rdata.get('description', 'ì„¤ëª… ì—†ìŒ'),
                    "ratio_type": rdata['type'],
                    "formula": rdata.get('formula_human'),
                    "unit": rdata.get('unit'),
                    "id": rid
                }
        
        # 3. ëª» ì°¾ìŒ
        return {
            "found": False,
            "message": f"'{term}'ì— ëŒ€í•œ ì •ì˜ë¥¼ config.jsonì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”."
        }
    
    def general_knowledge_qa(self, question: str) -> str:
        """ì¼ë°˜ ì¬ë¬´/ê²½ì˜ ì§€ì‹ ì œê³µ"""
        try:
            print(f"\n[DEBUG] ========================================")
            print(f"[DEBUG] general_knowledge_qa ì‹œì‘")
            print(f"[DEBUG] ì§ˆë¬¸: {question}")
            print(f"[DEBUG] ========================================")
            logging.info(f"general_knowledge_qa í˜¸ì¶œ: {question}")
            
            # [ì•ˆì „ ì¡°ì¹˜ 1] ëª¨ë¸ ìƒì„±
            print(f"[DEBUG] Gemini ëª¨ë¸ ìƒì„± ì¤‘...")
            model_simple = genai.GenerativeModel('models/gemini-flash-lite-latest')
            print(f"[DEBUG] Gemini ëª¨ë¸ ìƒì„± ì™„ë£Œ")
            
            # [ì•ˆì „ ì¡°ì¹˜ 2] API í˜¸ì¶œ ì „ ë¡œê·¸
            print(f"[DEBUG] Gemini API í˜¸ì¶œ ì‹œì‘ (ì§€ì‹ ì œê³µ)...")
            logging.debug("ì§€ì‹ ì œê³µ API í˜¸ì¶œ ì¤‘")
            
            response = model_simple.generate_content(
                f"""ë‹¹ì‹ ì€ ì¬ë¬´/ê²½ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì§ˆë¬¸ì— ìƒì„¸í•˜ê³  ì¹œì ˆí•˜ê²Œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:

{question}

ë‹µë³€ ì‹œ:
- ì •ì˜ì™€ ê°œë…ì„ ëª…í™•íˆ ì„¤ëª…
- ì‹¤ë¬´ì  ì˜ë¯¸ì™€ í™œìš© ë°©ë²• ì œê³µ
- êµ¬ì²´ì ì¸ ì˜ˆì‹œ í¬í•¨
- ì¼ë°˜ì ì¸ ê¸°ì¤€ì´ë‚˜ ì—…ê³„ í‰ê·  ì–¸ê¸‰ (ìˆë‹¤ë©´)
- 3-5 ë¬¸ë‹¨ìœ¼ë¡œ ì¶©ë¶„íˆ ìƒì„¸í•˜ê²Œ

ì „ë¬¸ì ì´ì§€ë§Œ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.""",
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=1500,
                    temperature=0.3
                )
            )
            
            print(f"[DEBUG] Gemini API ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ")
            print(f"[DEBUG] ì‘ë‹µ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(response.text)}ì")
            print(f"[DEBUG] general_knowledge_qa ì™„ë£Œ")
            logging.info("ì§€ì‹ ì œê³µ ì™„ë£Œ")
            
            return response.text
            
        except Exception as e:
            print(f"\n[CRITICAL ERROR] general_knowledge_qa ì‹¤íŒ¨!")
            print(f"ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
            print(f"ì˜¤ë¥˜ ë©”ì‹œì§€: {str(e)}")
            logging.error(f"ì¼ë°˜ ì§€ì‹ ì œê³µ ì˜¤ë¥˜: {e}", exc_info=True)
            
            import traceback
            traceback.print_exc()
            
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì§€ì‹ ì œê³µ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\nì˜¤ë¥˜: {type(e).__name__}\nì§ˆë¬¸ì„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    def _parse_final_answer_to_structured_format(self, final_answer: str):
        """
        ìµœì¢… ë§ˆí¬ë‹¤ìš´ ë‹µë³€ì„ í”„ë¡ íŠ¸ì—”ë“œê°€ ìš”êµ¬í•˜ëŠ” JSON êµ¬ì¡°ë¡œ ìœ ì—°í•˜ê²Œ íŒŒì‹±í•©ë‹ˆë‹¤.
        '### ìˆ«ì. ì œëª©' í˜•ì‹ì˜ ëª¨ë“  ì„¹ì…˜ì„ ì¸ì‹í•©ë‹ˆë‹¤.
        """
        import re
        
        content_blocks = []
        
        # 0. ì°¨íŠ¸ê°€ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸ (ìµœìš°ì„ )
        if self.last_chart_data and self.last_chart_data.get('image_base64'):
            if "ì°¨íŠ¸" in final_answer or "ê·¸ë˜í”„" in final_answer:
                content_blocks.append({
                    "type": "chart",
                    "content": {
                        "image_base64": self.last_chart_data['image_base64'],
                        "file_path": self.last_chart_data.get('file_path', '')
                    }
                })
                # ì°¨íŠ¸ í¬í•¨ ì‹œ ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ë§Œ ì¶”ê°€
                simple_text = re.sub(r'íŒŒì¼ ê²½ë¡œ:.*', '', final_answer).strip()
                if simple_text:
                    content_blocks.append({"type": "text", "content": simple_text})
                
                # ì°¨íŠ¸ ë°ì´í„° ì´ˆê¸°í™” (ì¬ì‚¬ìš© ë°©ì§€)
                self.last_chart_data = None
                
                return content_blocks
        
        # 1. '### ìˆ«ì.' íŒ¨í„´ì„ ê¸°ì¤€ìœ¼ë¡œ ì „ì²´ ë‹µë³€ì„ ì„¹ì…˜ìœ¼ë¡œ ë¶„ë¦¬ (ìœ ì—°ì„±)
        sections = re.split(r'\n(?=###\s*\d+\.\s*)', final_answer.strip())
        
        for section in sections:
            section_content = section.strip()
            if not section_content:
                continue
            
            # 2. ê° ì„¹ì…˜ì´ í…Œì´ë¸”ì¸ì§€ ê²€ì‚¬ (ì§€ëŠ¥)
            lines = [line.strip() for line in section_content.split('\n') if line.strip()]
            
            # í…Œì´ë¸” íŒë‹¨: ìµœì†Œ 3ì¤„, ì²« ì¤„ì— |, ë‘ ë²ˆì§¸ ì¤„ì— ---, ë‚˜ë¨¸ì§€ì—ë„ |
            is_table_section = False
            if len(lines) >= 3:
                if '|' in lines[0] and '---' in lines[1]:
                    if any('|' in line for line in lines[2:]):
                        is_table_section = True
            
            if is_table_section:
                # 3-A. í…Œì´ë¸”ì´ë©´ êµ¬ì¡°í™”ëœ JSONìœ¼ë¡œ ë³€í™˜
                try:
                    # í…Œì´ë¸” ì‹œì‘ ì¸ë±ìŠ¤ ì°¾ê¸° (ì œëª© ì œì™¸)
                    table_start = 0
                    for i, line in enumerate(lines):
                        if '|' in line and i < len(lines) - 1 and '---' in lines[i+1]:
                            table_start = i
                            break
                    
                    # í—¤ë”ì™€ í–‰ íŒŒì‹±
                    columns = [h.strip() for h in lines[table_start].strip('|').split('|')]
                    rows = []
                    for line in lines[table_start+2:]:  # í—¤ë”ì™€ êµ¬ë¶„ì ê±´ë„ˆë›°ê¸°
                        if '|' in line:
                            rows.append([r.strip() for r in line.strip('|').split('|')])
                    
                    # InteractiveTableì„ ìœ„í•œ êµ¬ì¡°
                    content_blocks.append({
                        "type": "table",
                        "content": {"columns": columns, "rows": rows}
                    })
                    
                    # í…Œì´ë¸” ìœ„ì˜ ì œëª©ì´ ìˆìœ¼ë©´ ë³„ë„ í…ìŠ¤íŠ¸ë¡œ ì¶”ê°€
                    if table_start > 0:
                        prefix = '\n'.join(lines[:table_start])
                        if prefix.strip():
                            # ì œëª©ì„ í…Œì´ë¸” ì•ì— ì¶”ê°€
                            content_blocks.insert(-1, {"type": "text", "content": prefix.strip()})
                    
                except Exception as e:
                    logging.warning(f"í…Œì´ë¸” íŒŒì‹± ì‹¤íŒ¨, í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬: {e}")
                    content_blocks.append({"type": "text", "content": section_content})
            else:
                # 3-B. í…Œì´ë¸” ì•„ë‹ˆë©´ í…ìŠ¤íŠ¸ë¡œ
                content_blocks.append({"type": "text", "content": section_content})
        
        # 2. ì•ˆë‚´ ë©”ì‹œì§€ (ğŸ’¡ë¡œ ì‹œì‘) - ë³„ë„ ì²˜ë¦¬
        notice_match = re.search(r"(ğŸ’¡.*?)(?=\n\n|\Z)", final_answer, re.DOTALL)
        if notice_match:
            # ì´ë¯¸ í…ìŠ¤íŠ¸ ë¸”ë¡ì— í¬í•¨ë˜ì—ˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì¤‘ë³µ ì²´í¬
            notice_text = notice_match.group(1).strip()
            # ë§ˆì§€ë§‰ ë¸”ë¡ì— ì´ë¯¸ í¬í•¨ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ ì¶”ê°€
            if not content_blocks or notice_text not in content_blocks[-1].get("content", ""):
                content_blocks.append({"type": "notice", "content": notice_text})
        
        # íŒŒì‹±ëœ ë¸”ë¡ì´ ì—†ìœ¼ë©´, ì „ì²´ ë‹µë³€ì„ ë‹¨ì¼ í…ìŠ¤íŠ¸ ë¸”ë¡ìœ¼ë¡œ ë°˜í™˜
        if not content_blocks:
            return [{"type": "text", "content": final_answer}]
            
        return content_blocks
    
    def run_and_get_structured_output(self, user_query: str):
        """
        APIìš© ì‹¤í–‰ ë©”ì„œë“œ - êµ¬ì¡°í™”ëœ JSON ë°˜í™˜
        ê¸°ì¡´ run() ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ë˜, ì¶œë ¥ì„ ìº¡ì²˜í•˜ì—¬ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        import io
        import sys
        
        # í‘œì¤€ ì¶œë ¥ ìº¡ì²˜ ì¤€ë¹„
        old_stdout = sys.stdout
        sys.stdout = captured_output = io.StringIO()
        
        final_answer = None
        
        try:
            # ê¸°ì¡´ run() ë©”ì„œë“œì˜ ë¡œì§ì„ ì¬ì‚¬ìš©
            # run() ë‚´ë¶€ì—ì„œ ìµœì¢… ë‹µë³€ì´ ì¶œë ¥ë˜ë¯€ë¡œ ì´ë¥¼ ìº¡ì²˜í•©ë‹ˆë‹¤
            
            # run() ë©”ì„œë“œ ì‹¤í–‰
            self.run(user_query)
            
            # ì¶œë ¥ëœ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
            output = captured_output.getvalue()
            
            # [GMIS Agent v4] ì´í›„ì˜ ë‚´ìš©ì„ ìµœì¢… ë‹µë³€ìœ¼ë¡œ ì¶”ì¶œ
            if "[GMIS Agent v4]" in output:
                parts = output.split("[GMIS Agent v4]")
                if len(parts) > 1:
                    final_answer = parts[-1].strip()
            
            # ìµœì¢… ë‹µë³€ì´ ì—†ìœ¼ë©´ ì „ì²´ ì¶œë ¥ ì‚¬ìš©
            if not final_answer:
                final_answer = output.strip()
            
            # ë””ë²„ê·¸/í’ˆì§ˆ ê²½ê³  ë©”ì‹œì§€ ì œê±° (ì‚¬ìš©ìì—ê²Œ ë³´ì´ì§€ ì•Šì•„ì•¼ í•¨)
            # ì¤„ì˜ ì‹œì‘ ë¶€ë¶„ì— ìˆëŠ” ê²½ìš°ë§Œ ì œê±° (^ ì‚¬ìš©)
            debug_patterns = [
                r'^\[í’ˆì§ˆ ê²½ê³ \].*?$',
                r'^\[DEBUG\].*?$',
                r'^\[ê²½ê³ \].*?$',
                r'^\[íŒíŠ¸\].*?$',
                r'^\[ì‘ì—…\].*?$',
                r'^\[ì‚¬ê³ \].*?$'
            ]
            import re
            for pattern in debug_patterns:
                final_answer = re.sub(pattern, '', final_answer, flags=re.MULTILINE)
            
            # ì—°ì†ëœ ë¹ˆ ì¤„ ì •ë¦¬
            final_answer = re.sub(r'\n\n\n+', '\n\n', final_answer).strip()
            
            # API ì‘ë‹µ ë¡œê¹… (ë””ë²„ê¹…ìš©)
            logging.info(f"ìµœì¢… ë‹µë³€ (íŒŒì‹± ì „): {final_answer[:500]}...")  # ì²˜ìŒ 500ìë§Œ
                
        except Exception as e:
            logging.error(f"run_and_get_structured_output ì˜¤ë¥˜: {e}", exc_info=True)
            final_answer = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        finally:
            # í‘œì¤€ ì¶œë ¥ ë³µì›
            sys.stdout = old_stdout
        
        # ë§ˆí¬ë‹¤ìš´ ë‹µë³€ì„ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ íŒŒì‹± ì‹œë„
        try:
            structured_content = self._parse_final_answer_to_structured_format(final_answer)
            
            # íŒŒì‹± ê²°ê³¼ ë¡œê¹…
            logging.info(f"íŒŒì‹±ëœ ì»¨í…ì¸  ë¸”ë¡ ìˆ˜: {len(structured_content)}")
            
            # íŒŒì‹± ê²°ê³¼ê°€ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ ë¸”ë¡ë¿ì´ê³ , ì›ë³¸ì— í…Œì´ë¸”ì´ ìˆë‹¤ë©´ íŒŒì‹± ì‹¤íŒ¨ë¡œ ê°„ì£¼
            if len(structured_content) == 1 and structured_content[0]['type'] == 'text':
                if '|' in final_answer and '---' in final_answer and '###' in final_answer:
                    logging.warning("í…Œì´ë¸”ì´ í¬í•¨ëœ ë‹µë³€ì´ì§€ë§Œ íŒŒì‹± ì‹¤íŒ¨. ì „ì²´ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.")
            
            return structured_content
            
        except Exception as parse_error:
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì „ì²´ ë‹µë³€ì„ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜
            logging.error(f"íŒŒì‹± ì‹¤íŒ¨: {parse_error}. ì „ì²´ ë‹µë³€ì„ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.")
            return [{"type": "text", "content": final_answer}]
    
    def _determine_level(self, user_query):
        """LLMì„ í™œìš©í•œ ì „ì‚¬ vs ì‚¬ì—…ë³„ ë ˆë²¨ íŒë‹¨ (ê°œì„ )"""
        level_detection_prompt = f"""Analyze this user query: "{user_query}"

Determine if the user wants:
- CORPORATE: Company-wide totals (íšŒì‚¬ ì „ì²´, ì—°ê²°/ë³„ë„ ê¸°ì¤€, ë¶„ê¸°/ì—°ê°„ í•©ê³„)
  Keywords: íšŒì‚¬ ë¹„êµ, ì „ë…„ ëŒ€ë¹„, ë¶„ê¸°, ì—°ê°„, ì—°ê²° ê¸°ì¤€, ë³„ë„ ê¸°ì¤€, ì´ë§¤ì¶œ, ì „ì²´
  Examples: "ì¼ë ‰íŠ¸ë¦­ê³¼ ì „ì„ ì˜ ë§¤ì¶œ", "3ë¶„ê¸° ì˜ì—…ì´ìµ", "ì—°ê²° ê¸°ì¤€ ìì‚°", "ì—°ê°„ ë§¤ì¶œ"
  
- SEGMENT: Business unit/segment queries (ì‚¬ì—… ëª©ë¡, ì‚¬ì—…ë³„ ìƒì„¸, í¬íŠ¸í´ë¦¬ì˜¤)
  Keywords: ì‚¬ì—…ë³„, ë¶€ë¬¸ë³„, ì œí’ˆêµ°ë³„, í¬íŠ¸í´ë¦¬ì˜¤, "ì–´ë–¤ ì‚¬ì—…", "ì‚¬ì—… í•­ëª©", "ì‚¬ì—…ì€", CICë³„
  Examples: "ì–´ë–¤ ì‚¬ì—…ì´ ìˆì–´?", "ì‚¬ì—… í•­ëª©ì€?", "ì‚¬ì—…ë³„ ë§¤ì¶œ", "CICë³„ë¡œ"

**IMPORTANT:** "ì–´ë–¤ ì‚¬ì—…", "ì‚¬ì—… í•­ëª©", "CICë³„" â†’ SEGMENT ë ˆë²¨ì…ë‹ˆë‹¤!

Respond with ONLY one word: CORPORATE or SEGMENT"""

        try:
            print(f"[DEBUG] _determine_level ì‹œì‘: {user_query[:50]}...")
            logging.debug(f"ë ˆë²¨ íŒë‹¨ ì§ˆë¬¸: {user_query}")
            
            print(f"[DEBUG] Gemini ëª¨ë¸ ìƒì„± ì¤‘ (ë ˆë²¨ íŒë‹¨)...")
            model_simple = genai.GenerativeModel('models/gemini-flash-lite-latest')
            
            print(f"[DEBUG] Gemini API í˜¸ì¶œ ì¤‘ (ë ˆë²¨ íŒë‹¨)...")
            response = model_simple.generate_content(
                level_detection_prompt,
                generation_config=genai.types.GenerationConfig(max_output_tokens=10, temperature=0.0)
            )
            
            print(f"[DEBUG] Gemini API ì‘ë‹µ ìˆ˜ì‹  (ë ˆë²¨ íŒë‹¨)")
            level = response.text.strip().upper()
            
            if level not in ["CORPORATE", "SEGMENT"]:
                logging.warning(f"ì˜ˆìƒì¹˜ ëª»í•œ ë ˆë²¨ ì‘ë‹µ: {level}, ê¸°ë³¸ê°’ ì‚¬ìš©")
                level = "CORPORATE"
            
            print(f"[ë¶„ì„] ì¿¼ë¦¬ ë ˆë²¨: {level}")
            logging.info(f"ë ˆë²¨ íŒë‹¨ ê²°ê³¼: {level}")
            return level
            
        except Exception as e:
            print(f"[ê²½ê³ ] ë ˆë²¨ íŒë‹¨ ì‹¤íŒ¨, ê¸°ë³¸ê°’(CORPORATE) ì‚¬ìš©")
            print(f"  ì˜¤ë¥˜: {type(e).__name__}: {str(e)[:200]}")
            logging.warning(f"ë ˆë²¨ íŒë‹¨ ì‹¤íŒ¨: {e}", exc_info=True)
            return "CORPORATE"
    
    def _validate_query(self, query):
        """Cypher ì¿¼ë¦¬ ì‚¬ì „ ê²€ì¦ + available_data ì²´í¬"""
        warnings = []
        
        if "fs.year" in query or "fs.month" in query:
            warnings.append("âš ï¸ FinancialStatementì—ëŠ” year/month ì†ì„±ì´ ì—†ìŠµë‹ˆë‹¤. fs.id CONTAINS ì‚¬ìš©")
        
        if ("c.name =" in query or "company.name =" in query) and "Company" in query:
            warnings.append("âš ï¸ CompanyëŠ” c.idë¡œ ë§¤ì¹­í•˜ì„¸ìš”. ì˜ˆ: {id: 'ELECTRIC'}")
        
        if "v.region" in query and "HAS_STATEMENT" in query and "FOR_SEGMENT" not in query:
            warnings.append("âš ï¸ CORPORATE ë°ì´í„°ì—ëŠ” v.region ì†ì„±ì´ ì—†ìŠµë‹ˆë‹¤. í•„í„° ì œê±° í•„ìš”")
        
        # Phase 6: available_data ì²´í¬
        import re
        # ì¿¼ë¦¬ì—ì„œ íšŒì‚¬ ID ì¶”ì¶œ
        company_match = re.search(r"c\.id\s*=\s*'([^']+)'|c\.id\s*IN\s*\[([^\]]+)\]", query)
        if company_match:
            company_ids = []
            if company_match.group(1):
                company_ids = [company_match.group(1)]
            else:
                # IN [...] í˜•ì‹
                ids_str = company_match.group(2)
                company_ids = [cid.strip().strip("'\"") for cid in ids_str.split(',')]
            
            # ê° íšŒì‚¬ì˜ available_data ì²´í¬
            for cid in company_ids:
                company_config = self.config['entities']['companies'].get(cid)
                if company_config:
                    avail_data = company_config.get('available_data', [])
                    
                    # BS ë°ì´í„° ìš”ì²­í–ˆëŠ”ë° ì—†ëŠ” ê²½ìš°
                    if ':BS' in query and 'BS' not in avail_data:
                        warnings.append(f"âš ï¸ {company_config.get('official_name', cid)}ì€(ëŠ”) BS ë°ì´í„°ê°€ ì œê³µë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    
                    # IS ë°ì´í„° ìš”ì²­í–ˆëŠ”ë° ì—†ëŠ” ê²½ìš°  
                    if ':IS' in query and 'IS' not in avail_data:
                        warnings.append(f"âš ï¸ {company_config.get('official_name', cid)}ì€(ëŠ”) IS ë°ì´í„°ê°€ ì œê³µë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        return warnings
    
    def _validate_answer_format(self, answer):
        """GENEROUS ë‹µë³€ ì „ëµ ì¤€ìˆ˜ ì—¬ë¶€ ê²€ì¦ (v3 ë™ì¼)"""
        score = 0
        
        # êµ¬ì¡°í™”ëœ ì„¹ì…˜ í™•ì¸
        if "###" in answer or "##" in answer:
            score += 1
        
        # í…Œì´ë¸” í˜•ì‹ í™•ì¸
        if "|" in answer and "---" in answer:
            score += 1
        
        # í•µì‹¬ í‚¤ì›Œë“œ í™•ì¸
        keywords = ["ìš”ì•½", "ì§‘ê³„", "ì›”ë³„", "ìƒì„¸", "ë¶„ì„", "ì¸ì‚¬ì´íŠ¸"]
        if any(kw in answer for kw in keywords):
            score += 1
        
        return score
    
    def _summarize_history(self):
        """[ê°œì„ ] ëŒ€í™” íˆìŠ¤í† ë¦¬ ìš”ì•½ (ì•ˆì „ì¥ì¹˜ + ìë™ ë³µêµ¬)"""
        try:
            print("[ì‹œìŠ¤í…œ] ëŒ€í™” ë‚´ìš© ìš”ì•½ ì¤‘...")
            logging.info(f"ëŒ€í™” íˆìŠ¤í† ë¦¬ ìš”ì•½ ì‹œì‘ (í˜„ì¬: {len(self.chat_history)}ê°œ)")
            
            history_text = json.dumps(self.chat_history, ensure_ascii=False, indent=2)
            
            # ì•ˆì „ì¥ì¹˜: íˆìŠ¤í† ë¦¬ê°€ ë„ˆë¬´ í¬ë©´ ìš”ì•½ ì‹œë„í•˜ì§€ ì•ŠìŒ
            if len(history_text) > 20000:
                logging.warning(f"íˆìŠ¤í† ë¦¬ í¬ê¸° ê³¼ë‹¤ ({len(history_text)}ì). ìš”ì•½ ê±´ë„ˆë›°ê³  ì´ˆê¸°í™”")
                raise ValueError("History text is too long to summarize safely.")
            
            summary_prompt = f"ë‹¤ìŒ ëŒ€í™”ë¥¼ 3-5ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½:\n\n{history_text}\n\ní•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ:"
            
            model_simple = genai.GenerativeModel('models/gemini-flash-lite-latest')
            response = model_simple.generate_content(
                summary_prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=500,
                    temperature=0.2
                )
            )
            
            # ì‘ë‹µ ê²€ì¦
            if not response.candidates or not response.candidates[0].content.parts:
                raise ValueError("LLM returned an empty response for summarization.")
            
            summary = response.text
            self.chat_history = [
                {"role": "system", "content": f"[ì´ì „ ëŒ€í™” ìš”ì•½] {summary}"}
            ]
            print("[ì™„ë£Œ] ìš”ì•½ ì™„ë£Œ\n")
            logging.info("ëŒ€í™” íˆìŠ¤í† ë¦¬ ìš”ì•½ ì™„ë£Œ")
            
        except Exception as e:
            print(f"[ê²½ê³ ] ëŒ€í™” íˆìŠ¤í† ë¦¬ ìš”ì•½ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
            logging.warning(f"íˆìŠ¤í† ë¦¬ ìš”ì•½ ì‹¤íŒ¨: {e}", exc_info=True)
            
            # ìƒì„¸ ì˜¤ë¥˜ ìŠ¤íƒ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
            import traceback
            traceback.print_exc()
            
            # [í•µì‹¬] ìš”ì•½ ì‹¤íŒ¨ ì‹œ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™” (ì•ˆì „ ë³µêµ¬)
            self.chat_history = []
            print("[ì‹œìŠ¤í…œ] ì•ˆì •ì„±ì„ ìœ„í•´ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.\n")
            logging.warning("íˆìŠ¤í† ë¦¬ ìš”ì•½ ì‹¤íŒ¨ë¡œ ì¸í•œ ìë™ ì´ˆê¸°í™”")
    
    def _extract_entities(self, user_query):
        """ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì—”í‹°í‹°ë¥¼ ì¶”ì¶œí•˜ê³  NLUë¡œ ë§¤í•‘"""
        query_lower = user_query.lower()
        
        # ê·¸ë£¹ ì¶”ì¶œ (ìš°ì„  ì²˜ë¦¬)
        mentioned_groups = {}
        for alias, group_id in self.nlu['group'].items():
            if alias in query_lower:
                mentioned_groups[alias] = group_id
        
        # íšŒì‚¬ ì¶”ì¶œ
        mentioned_companies = {}
        for alias, company_id in self.nlu['company'].items():
            if alias in query_lower:
                mentioned_companies[alias] = company_id
        
        # ê³„ì • ì¶”ì¶œ  
        mentioned_accounts = {}
        for alias, account_id in self.nlu['account'].items():
            if alias in query_lower:
                mentioned_accounts[alias] = account_id
        
        return {
            "groups": mentioned_groups,
            "companies": mentioned_companies,
            "accounts": mentioned_accounts
        }
    
    def run(self, user_query: str):
        """[ê°œì„ ] ìƒíƒœ ê¸°ë°˜ ì˜ë„ ë¶„ë¥˜ê¸° + ë§ì¶¤í˜• í”„ë¡¬í”„íŠ¸"""
        
        # ì „ì²´ run() ë©”ì„œë“œë¥¼ ë³´í˜¸
        try:
            print(f"\n{'='*70}")
            print(f"[USER] {user_query}")
            print(f"{'='*70}")
            logging.info(f"ì‚¬ìš©ì ì§ˆë¬¸: {user_query}")
            
            # [í•µì‹¬ ê°œì„ ] ìƒíƒœ ê¸°ë°˜ ì˜ë„ ë¶„ë¥˜
            print(f"[DEBUG] í›„ì† ì‘ì—… ì—¬ë¶€ íŒë‹¨ ì¤‘...")
            is_follow_up = False
            follow_up_keywords = ["ê·¸ë˜í”„", "ì°¨íŠ¸", "ì‹œê°í™”", "csv", "íŒŒì¼", "ì €ì¥", "ë‹¤ìš´ë¡œë“œ"]
            
            if self.last_query_result and any(kw in user_query.lower() for kw in follow_up_keywords):
                is_follow_up = True
                print(f"[ë¶„ì„] í›„ì† ì‘ì—… ìš”ì²­ìœ¼ë¡œ íŒë‹¨")
                logging.info("í›„ì† ì‘ì—… ìš”ì²­ìœ¼ë¡œ íŒë‹¨ (ìºì‹œ ë°ì´í„° í™œìš©, ì¬ì¡°íšŒ ê±´ë„ˆë›°ê¸°)")
            else:
                print(f"[ë¶„ì„] ìƒˆë¡œìš´ ë°ì´í„° ì¡°íšŒ ë˜ëŠ” ì§ˆë¬¸ìœ¼ë¡œ íŒë‹¨")
            
            # ì—”í‹°í‹° ì¶”ì¶œ ë° NLU (ìƒˆ ì¡°íšŒ ì‹œì—ë§Œ í•„ìš”)
            if not is_follow_up:
                print(f"[DEBUG] ì—”í‹°í‹° ì¶”ì¶œ ì¤‘...")
                entities = self._extract_entities(user_query)
                
                # ì¶”ì¶œëœ ì—”í‹°í‹° ë¡œê¹…
                if entities.get("groups"):
                    print(f"[ì¶”ì¶œ] ê·¸ë£¹: {entities['groups']}")
                    logging.info(f"ì¶”ì¶œëœ ê·¸ë£¹: {entities['groups']}")
                if entities.get("companies"):
                    print(f"[ì¶”ì¶œ] íšŒì‚¬: {entities['companies']}")
                    logging.info(f"ì¶”ì¶œëœ íšŒì‚¬: {entities['companies']}")
                
                print(f"[DEBUG] ë ˆë²¨ íŒë‹¨ ì¤‘...")
                level = self._determine_level(user_query)
            else:
                entities = {}
                level = "CORPORATE"  # ì„ì‹œê°’
            
            level_guide = {
                "CORPORATE": "\n[CONTEXT] Use CORPORATE level: (c:Company)-[:HAS_STATEMENT]->(fs)",
                "SEGMENT": "\n[CONTEXT] Use SEGMENT level: (c:Company)-[:HAS_ALL_SEGMENTS]->(bs)"
            }
            
            # NLU ì»¨í…ìŠ¤íŠ¸ ìƒì„± (ìƒˆ ì¡°íšŒ ì‹œì—ë§Œ)
            priority_companies = ['ì „ì„ ', 'ì „ì„ (í™ì¹˜ì œì™¸)', 'lsì „ì„ ', 'electric', 'lsì¼ë ‰íŠ¸ë¦­', 
                                 'mnm', 'ì— ì•¤ì— ', 'ì•°ì—”ì— ', 'ì— íŠ¸ë¡ ', 'ì•°íŠ¸ë¡ ',
                                 'ì „ë ¥cic', 'ì „ë ¥', 'ìë™í™”cic', 'ìë™í™”']
            
            company_mapping_examples = {}
            for key in self.nlu['company'].keys():
                if any(p in key.lower() for p in priority_companies):
                    company_mapping_examples[key] = self.nlu['company'][key]
            
            for key, val in self.nlu['company'].items():
                if len(company_mapping_examples) >= 25:
                    break
                if key not in company_mapping_examples:
                    company_mapping_examples[key] = val
            
            # segment_to_main_account_mapping ì •ë³´ (configì—ì„œ ë™ì ìœ¼ë¡œ)
            segment_account_mapping = self.config.get('segment_to_main_account_mapping', {})
            
            # ê·¸ë£¹ êµ¬ì„±ì› ì •ë³´ (configì—ì„œ ë™ì ìœ¼ë¡œ)
            group_members = {}
            for group_id, group_data in self.config.get('business_rules', {}).get('company_groups', {}).items():
                members = []
                for company_id, company_data in self.config.get('entities', {}).get('companies', {}).items():
                    if group_id in company_data.get('groups', []):
                        members.append(f"{company_id} ({company_data['official_name']})")
                group_members[group_data['name']] = members
            
            # Special Handling ê·œì¹™ (configì—ì„œ ë™ì ìœ¼ë¡œ)
            special_rules = {}
            for rule_name, rule_data in self.config.get('business_rules', {}).get('special_handling', {}).items():
                if rule_name == 'use_adjusted_operating_income':
                    companies = rule_data.get('companies', [])
                    account_to_use = rule_data.get('account_to_use')
                    replaces = rule_data.get('replaces')
                    special_rules[rule_name] = {
                        "companies": companies,
                        "rule": f"For {', '.join(companies)}: Use '{account_to_use}' instead of '{replaces}'"
                    }
            
            # ì¶”ì¶œëœ ì—”í‹°í‹° ì •ë³´ (ìƒˆ ì¡°íšŒ ì‹œì—ë§Œ í•„ìš”)
            entity_context = ""
            
            # ê·¸ë£¹ì´ ì–¸ê¸‰ë˜ì—ˆìœ¼ë©´ í•´ë‹¹ ê·¸ë£¹ì˜ íšŒì‚¬ ëª©ë¡ì„ ëª…ì‹œì ìœ¼ë¡œ ì œê³µ
            if entities.get("groups"):
                entity_context += "\n**ğŸ¯ ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ íšŒì‚¬ ê·¸ë£¹ (CRITICAL!):**\n"
                for alias, group_id in entities["groups"].items():
                    group_name = self.config.get('business_rules', {}).get('company_groups', {}).get(group_id, {}).get('name', group_id)
                    # í•´ë‹¹ ê·¸ë£¹ì˜ ëª¨ë“  íšŒì‚¬ ID ì¶”ì¶œ
                    group_company_ids = []
                    for company_id, company_data in self.config.get('entities', {}).get('companies', {}).items():
                        if group_id in company_data.get('groups', []):
                            group_company_ids.append(company_id)
                    
                    # ë¡œê¹…ìœ¼ë¡œ í™•ì¸
                    print(f"[ê·¸ë£¹ ë§¤í•‘] '{alias}' â†’ {group_company_ids}")
                    logging.info(f"ê·¸ë£¹ '{alias}' ({group_id})ì˜ íšŒì‚¬ ëª©ë¡: {group_company_ids}")
                    
                    entity_context += f"- User said: '{alias}' â†’ Group: '{group_name}'\n"
                    entity_context += f"  **YOU MUST USE ALL THESE COMPANY IDs: {group_company_ids}**\n"
                    entity_context += f"  Example: WHERE c.id IN {group_company_ids}\n"
                    entity_context += f"  âš ï¸ Do NOT omit any company! Include ALL {len(group_company_ids)} companies!\n\n"
            
            if entities.get("companies"):
                entity_context += "\n**ğŸ¯ ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ íšŒì‚¬ (NLU ë§¤í•‘ ì™„ë£Œ):**\n"
                for alias, company_id in entities["companies"].items():
                    entity_context += f"- '{alias}' â†’ Company ID: '{company_id}' (ì´ IDë¥¼ ì¿¼ë¦¬ì— ì‚¬ìš©í•˜ì„¸ìš”!)\n"
            
            if entities.get("accounts"):
                entity_context += "\n**ğŸ¯ ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ ê³„ì • (NLU ë§¤í•‘ ì™„ë£Œ):**\n"
                for alias, account_id in entities["accounts"].items():
                    entity_context += f"- '{alias}' â†’ Account ID: '{account_id}' (ì´ IDë¥¼ ì¿¼ë¦¬ì— ì‚¬ìš©í•˜ì„¸ìš”!)\n"
            
            # Phase 7: contextual_ids ì¶”ê°€ (SEGMENT ë ˆë²¨ ì‹œ)
            if level == "SEGMENT":
                contextual_id_info = {}
                for cid, cdata in self.config['entities']['companies'].items():
                    if 'contextual_ids' in cdata and 'segment_data' in cdata['contextual_ids']:
                        contextual_id_info[cid] = {
                            "use_id": cdata['contextual_ids']['segment_data'],
                            "reason": "ì—°ê²° ì¬ë¬´ì œí‘œ íšŒì‚¬ì˜ ì‚¬ì—…ë³„ ë°ì´í„°ëŠ” ë³„ë„ ID ì‚¬ìš©"
                        }
                
                if contextual_id_info:
                    entity_context += "\n**ğŸ¯ Contextual ID Mapping (SEGMENT ë°ì´í„°ìš©):**\n"
                    entity_context += "ì¼ë¶€ íšŒì‚¬ëŠ” ì‚¬ì—…ë³„ ë°ì´í„° ì¡°íšŒ ì‹œ ë‹¤ë¥¸ IDë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤:\n"
                    for cid, info in contextual_id_info.items():
                        entity_context += f"- '{cid}' â†’ Use '{info['use_id']}' for segment queries\n"
                    entity_context += "\n"
            
            # json.dumps ê²°ê³¼ë¥¼ ë¨¼ì € ë³€ìˆ˜ì— ì €ì¥
            company_mapping_json = json.dumps(company_mapping_examples, ensure_ascii=False, indent=2)
            segment_mapping_json = json.dumps(segment_account_mapping, ensure_ascii=False, indent=2)
            group_members_json = json.dumps(group_members, ensure_ascii=False, indent=2)
            special_rules_json = json.dumps(special_rules, ensure_ascii=False, indent=2)
            
            # f-string ëŒ€ì‹  ë¬¸ìì—´ ì—°ê²° ì‚¬ìš© (JSON ì¤‘ê´„í˜¸ ì¶©ëŒ ë°©ì§€)
            nlu_context = entity_context + """

**Available Entity Mappings (ì°¸ê³ ìš©):**

Company Name â†’ ID:
""" + company_mapping_json + """

**Account ID ì°¾ê¸°:**
ëª¨ë“  ê³„ì •ì€ Term ë…¸ë“œë¥¼ í†µí•´ ì¡°íšŒí•˜ì„¸ìš”. í•˜ë“œì½”ë”© ê¸ˆì§€!

**Segment Account Mapping:**
""" + segment_mapping_json + """

**Company Groups:**
""" + group_members_json + """

**âš ï¸ Special Rules (íŠ¹ìˆ˜ ì²˜ë¦¬ ê·œì¹™):**
""" + special_rules_json + """
â†’ ì´ ê·œì¹™ì„ ë°˜ë“œì‹œ ì ìš©í•˜ì„¸ìš”!

**ğŸ’¡ ê³„ì • ID ì°¾ê¸° (ë¹„ì •í˜• í‘œí˜„ ì²˜ë¦¬):**
ì‚¬ìš©ìê°€ "ìë³¸ì´ê³„", "ì´ìë³¸", "ìˆœìì‚°" ë“± ë‹¤ì–‘í•˜ê²Œ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì •í™•í•œ Account IDë¥¼ ëª¨ë¥´ëŠ” ê²½ìš° **Term ë…¸ë“œë¥¼ í™œìš©**í•˜ì„¸ìš”:

Step 1: ì‚¬ìš©ì í‘œí˜„ìœ¼ë¡œ Account ID ì°¾ê¸°
```cypher
MATCH (t:Term {{value: 'ìë³¸ì´ê³„'}})<-[:ALSO_KNOWN_AS]-(a:Account)
RETURN a.id, a.name
```
â†’ Returns: {{'a.id': 'ìê¸°ìë³¸_í•©ê³„', 'a.name': 'ìê¸°ìë³¸ í•©ê³„'}}

Step 2: ì°¾ì€ a.idë¥¼ ì‹¤ì œ ë°ì´í„° ì¿¼ë¦¬ì— ì‚¬ìš©

ì´ ë°©ë²•ìœ¼ë¡œ **ëª¨ë“  ê³„ì •ì˜ ë³„ì¹­**ì„ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!

**ğŸš¨ CRITICAL: ì—°ê²°/ë³„ë„ ì²˜ë¦¬ ê·œì¹™ (ì¼ê´€ì„± í•„ìˆ˜!):**

**ğŸ¯ SIMPLE DEFAULT RULES (ë°ì´í„° ê³¼ë¶€í•˜ ë°©ì§€!):**

**Rule 1: ì—°ê²° ìš°ì„  (ë³„ë„ëŠ” ëª…ì‹œ ìš”ì²­ ì‹œë§Œ)**
- **ê¸°ë³¸**: ì—°ê²°(CONSOLIDATED) ë°ì´í„°ë§Œ ì¡°íšŒ
- **ì˜ˆì™¸**: ì‚¬ìš©ìê°€ "ë³„ë„", "SEPARATE" ëª…ì‹œ ì‹œì—ë§Œ ë³„ë„ ì¡°íšŒ
- LSì „ì„ : 'LSCNS_C' (ì—°ê²°ë§Œ)
- MnM, ELECTRIC ë“±: `WHERE c.id = 'MnM'`ì™€ í•¨ê»˜
  ```cypher
  MATCH (fs)-[:HAS_SCOPE]->(scope:StatementScope {id: 'CONSOLIDATED'})
  ```
  **ì£¼ì˜**: `fs.scope` ì†ì„±ì€ ì—†ìŒ! HAS_SCOPE ê´€ê³„ ì‚¬ìš©!
- **ë‹µë³€ ì•ˆë‚´**: "ğŸ’¡ ì—°ê²° ì¬ë¬´ì œí‘œ ê¸°ì¤€ì…ë‹ˆë‹¤. ë³„ë„ ê¸°ì¤€ì´ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”."

**Rule 2: ì¡°ì •ì˜ì—…ì´ìµ (Special Rules ì°¸ì¡°)**
- ë™ì  ì»¨í…ìŠ¤íŠ¸ì˜ **'Special Rules'** ì„¹ì…˜ í™•ì¸
- í•´ë‹¹ íšŒì‚¬ê°€ ì¡°ì •ì˜ì—…ì´ìµ ì‚¬ìš© íšŒì‚¬ì¸ì§€ í™•ì¸
- **ê¸°ë³¸**: ì¡°ì •ì˜ì—…ì´ìµë§Œ ì¡°íšŒ
- **ì˜ˆì™¸**: ì‚¬ìš©ìê°€ "ì˜ì—…ì´ìµë„" ë˜ëŠ” "ë‘˜ ë‹¤" ëª…ì‹œ ì‹œ
- **ë‹µë³€ ì•ˆë‚´**: "ğŸ’¡ [íšŒì‚¬ëª…]ì€ ì¡°ì •ì˜ì—…ì´ìµ ê¸°ì¤€ì…ë‹ˆë‹¤."

**Rule 3: ë¹„êµ ìš”ì²­ ì‹œë§Œ í™•ì¥**
- "ë¹„êµ", "ì°¨ì´", "ë‘˜ ë‹¤" ëª…ì‹œ ì‹œ:
  â†’ ì—°ê²° + ë³„ë„ or ì˜ì—…ì´ìµ + ì¡°ì •ì˜ì—…ì´ìµ
- ê¸°ë³¸ì ìœ¼ë¡œëŠ” **í•˜ë‚˜ë§Œ** ì¡°íšŒ (ì†ë„ ë° ëª…í™•ì„± ìš°ì„ )

**Why?**
- 144ê°œ ë ˆì½”ë“œ â†’ 48ê°œ ë ˆì½”ë“œ (70% ê°ì†Œ)
- Gemini ì²˜ë¦¬ ë¶€ë‹´ ê°ì†Œ
- ë¹ ë¥´ê³  ëª…í™•í•œ ë‹µë³€
- í•„ìš” ì‹œ ì¶”ê°€ ì¡°íšŒ ê°€ëŠ¥
"""
            
            # íˆìŠ¤í† ë¦¬ëŠ” Chat Sessionì´ ìë™ ê´€ë¦¬ (ìˆ˜ë™ ì¶”ê°€ ë¶ˆí•„ìš”)
            
            # Tools (ëª¨ë“  ë„êµ¬ í¬í•¨)
            tools = [
                self.run_cypher_query,
                self.data_visualization,
                self.generate_downloadable_link,
                self.calculate_financial_ratio,  # Phase 3: ì¬ë¬´ë¹„ìœ¨ ê³„ì‚°
                self.get_ratios_by_viewpoint,    # Phase 5: ê´€ì ë³„ ë¹„ìœ¨ ëª©ë¡
                self.get_definition,             # Phase 4: ìš©ì–´ ì •ì˜
                self.general_knowledge_qa
            ]
            
            # [í•µì‹¬ ê°œì„ ] ìƒíƒœì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ ë¶„ê¸°
            
            if is_follow_up:
                # [í•µì‹¬ ê°œì„ ] ìºì‹œ ë°ì´í„°ì˜ ì‹¤ì œ ì»¬ëŸ¼ ëª©ë¡ ì¶”ì¶œ
                try:
                    if "columns" in self.last_query_result and self.last_query_result["columns"]:
                        available_columns = self.last_query_result["columns"]
                    else:
                        available_columns = list(pd.DataFrame(self.last_query_result["data"]).columns)
                except Exception as e:
                    logging.error(f"ìºì‹œ ë°ì´í„° ì»¬ëŸ¼ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                    available_columns = []
                
                # Case 1: í›„ì† ì‘ì—… - ê¸°ì¡´ chat ê°ì²´ ì¬ì‚¬ìš©
                current_prompt = f"""You are a focused tool-calling agent.

**Your ONLY task**: Fulfill this follow-up request using previously cached data.

User's request: "{user_query}"

**Available Data Columns in Cache**:
{available_columns}

**CRITICAL Instructions for Chart Generation**:
1. **DO NOT call run_cypher_query!** Use cached data only.

2. **For data_visualization**, use these parameters:
   ```python
   data_visualization(
       chart_type='line' or 'bar',
       title='ì°¨íŠ¸ ì œëª©',
       x_col='p.month',  # Time axis
       y_cols=['v.value'],  # Value axis
       company_filter='íšŒì‚¬ëª…',  # IMPORTANT! Extract from user request
       account_filter='ê³„ì •ëª…',   # IMPORTANT! Extract from user request
       year_filter=2022 or 2023,  # CRITICAL! If user specifies year
       show_trendline=True  # If user asks for "ì¶”ì„¸ì„ ", "trendline", "íšŒê·€ì„ "
   )
   ```

3. **Extract filters from user's request**:
   - "ì „ì„ ì˜ ë§¤ì¶œ" â†’ company_filter='ì „ì„ ', account_filter='ë§¤ì¶œ'
   - "ELECTRIC ì˜ì—…ì´ìµ" â†’ company_filter='ELECTRIC', account_filter='ì˜ì—…ì´ìµ'
   - "2022ë…„ ë§¤ì¶œ" â†’ year_filter=2022, account_filter='ë§¤ì¶œ'
   - "2023ë…„ ì¼ë ‰íŠ¸ë¦­" â†’ year_filter=2023, company_filter='ELECTRIC'
   
4. **CRITICAL for year filters**:
   - If user says "2022ë…„", "2023ë…„", "2024ë…„" â†’ ALWAYS use year_filter
   - Do NOT show multiple years when user asks for one specific year
   
5. **DO NOT try to find combined column names** like 'LSì „ì„ (ì—°ê²°) ë§¤ì¶œì•¡ í•©ê³„'!
   The data has separate columns: c.name, a.name, v.value
   Use filters to select specific company and account.

6. After tool success: Simple confirmation only!

Example:
"ìš”ì²­í•˜ì‹  ì°¨íŠ¸ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œ: [path]"
"""
                logging.info(f"í›„ì† ì‘ì—… ì „ìš© í”„ë¡¬í”„íŠ¸ ì‚¬ìš©. ì‚¬ìš© ê°€ëŠ¥ ì»¬ëŸ¼: {available_columns}")
                
            else:
                # Case 2: ìƒˆ ì¡°íšŒ
                # [í•µì‹¬ ìˆ˜ì •] chat ê°ì²´ê°€ ì—†ìœ¼ë©´ ìƒì„±, ìˆìœ¼ë©´ ì¬ì‚¬ìš©
                if self.chat is None:
                    # ì²« ëŒ€í™” - ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¡œ ì´ˆê¸°í™”
                    logging.info("ì²« ëŒ€í™” ì‹œì‘ - chat ê°ì²´ ìƒì„±")
                    self.chat = self.model.start_chat(
                        history=[
                            {'role': 'user', 'parts': [self.system_prompt]},
                            {'role': 'model', 'parts': ["OK. I am GMIS Agent v4. Ready for user question."]}
                        ],
                        enable_automatic_function_calling=False
                    )
                else:
                    # ê¸°ì¡´ chat ê°ì²´ ì¬ì‚¬ìš© (ëŒ€í™” ë§¥ë½ ìœ ì§€)
                    logging.info(f"ê¸°ì¡´ chat ê°ì²´ ì¬ì‚¬ìš© (íˆìŠ¤í† ë¦¬: {len(self.chat.history)}ê°œ ë©”ì‹œì§€)")
                
                current_prompt = f"{nlu_context}{level_guide.get(level, '')}\n\n[USER QUESTION]\n{user_query}"
                logging.info("ìƒˆ ë°ì´í„° ì¡°íšŒ - ì „ì²´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©")
            
            # [ìµœì¢… ìˆ˜ì •] chat ë³€ìˆ˜ ì•ˆì „í•˜ê²Œ ì°¸ì¡°
            # chatì´ Noneì´ë©´ ì¬ìƒì„± (íˆìŠ¤í† ë¦¬ ì •ë¦¬ í›„ ì‹œë‚˜ë¦¬ì˜¤)
            if self.chat is None:
                logging.warning("chat ê°ì²´ê°€ Noneì…ë‹ˆë‹¤. ì¬ìƒì„±í•©ë‹ˆë‹¤.")
                print("[ì‹œìŠ¤í…œ] ìƒˆë¡œìš´ ëŒ€í™” ì„¸ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                self.chat = self.model.start_chat(
                    history=[
                        {'role': 'user', 'parts': [self.system_prompt]},
                        {'role': 'model', 'parts': ["OK. I am GMIS Agent v4. Ready for user question."]}
                    ],
                    enable_automatic_function_calling=False
                )
            
            chat = self.chat
            logging.info(f"chat ê°ì²´ ì‚¬ìš© (íˆìŠ¤í† ë¦¬: {len(chat.history) if hasattr(chat, 'history') else 'unknown'}ê°œ)")
            
            # [ê°œì„ 1] íŒŒë¼ë¯¸í„°í™”ëœ ë°˜ë³µíšŸìˆ˜ ì‚¬ìš©
            for iteration in range(self.max_iterations):
                logging.info(f"ReAct Iteration {iteration + 1}/{self.max_iterations}")
                print(f"[DEBUG] === Iteration {iteration + 1} ì‹œì‘ ===")
                # [Turn X]ëŠ” ì‚¬ìš©ìì—ê²Œ ë³´ì´ì§€ ì•Šë„ë¡ loggingìœ¼ë¡œ ì´ë™
                
                # [ê¸´ê¸‰ ìˆ˜ì •] Gemini API í˜¸ì¶œì„ try-exceptë¡œ ë³´í˜¸
                try:
                    print(f"[DEBUG] Gemini API í˜¸ì¶œ ì¤‘... (í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(current_prompt)}ì)")
                    logging.debug(f"í˜„ì¬ í”„ë¡¬í”„íŠ¸ ì•ë¶€ë¶„: {current_prompt[:200]}...")
                    
                    response = chat.send_message(
                        current_prompt,
                        tools=tools,
                        generation_config=genai.types.GenerationConfig(
                            max_output_tokens=6000,  # ë‹µë³€ ì˜ë¦¼ ë°©ì§€ (4000 â†’ 6000)
                            temperature=0.1
                        )
                    )
                    print(f"[DEBUG] Gemini API ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ")
                    logging.debug("Gemini API ì‘ë‹µ ì„±ê³µ")
                    
                except Exception as api_error:
                    print(f"\n[CRITICAL ERROR] Gemini API í˜¸ì¶œ ì‹¤íŒ¨!")
                    print(f"ì˜¤ë¥˜ íƒ€ì…: {type(api_error).__name__}")
                    print(f"ì˜¤ë¥˜ ë©”ì‹œì§€: {str(api_error)[:500]}")
                    logging.error(f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {api_error}", exc_info=True)
                    
                    # ì‚¬ìš©ìì—ê²Œ ì˜¤ë¥˜ ì•Œë¦¼
                    print("\n[ì‹œìŠ¤í…œ] API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    return  # run ë©”ì„œë“œ ì•ˆì „í•˜ê²Œ ì¢…ë£Œ
                
                # ì‘ë‹µ ê²€ì¦ (ì•ˆì „ì„± ê°•í™”)
                if not response.candidates or not response.candidates[0].content.parts:
                    logging.warning("Geminiê°€ ë¹ˆ ì‘ë‹µì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤.")
                    current_prompt = "Please provide your analysis or next action."
                    continue
                
                part = response.candidates[0].content.parts[0]
                
                # Function Call í™•ì¸
                if hasattr(part, 'function_call') and part.function_call:
                    function_call = part.function_call
                    tool_name = function_call.name
                    tool_args = dict(function_call.args)
                    
                    logging.info(f"Tool í˜¸ì¶œ: {tool_name}")
                    print(f"[ì‚¬ê³ ] Tool '{tool_name}' í˜¸ì¶œ í•„ìš”")
                    
                    # ìƒíƒœ ë©”ì‹œì§€ (v3)
                    status_messages = {
                        "run_cypher_query": "[DB] ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì •ë³´ë¥¼ ì¡°íšŒí•˜ê³  ìˆìŠµë‹ˆë‹¤...",
                        "data_visualization": "[ì°¨íŠ¸] ì°¨íŠ¸ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...",
                        "generate_downloadable_link": "[íŒŒì¼] íŒŒì¼ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."
                    }
                    if tool_name in status_messages:
                        print(f"[ì‘ì—…] {status_messages[tool_name]}")
                    
                    # Tool ì‹¤í–‰
                    if tool_name == "run_cypher_query":
                        query_text = tool_args.get('query', '')
                        print(f"[Query]\n{query_text}\n")
                        
                        # WHERE c.id IN ë¶€ë¶„ì„ ë¡œê¹…í•´ì„œ ì— íŠ¸ë¡  í¬í•¨ ì—¬ë¶€ í™•ì¸
                        if "WHERE c.id IN" in query_text or "WHERE c.id =" in query_text:
                            import re
                            where_match = re.search(r"WHERE c\.id (?:IN\s*\[(.*?)\]|=\s*'(.*?)')", query_text)
                            if where_match:
                                company_ids = where_match.group(1) or where_match.group(2)
                                print(f"[í™•ì¸] ì¿¼ë¦¬ì— í¬í•¨ëœ íšŒì‚¬: {company_ids}")
                                logging.warning(f"ì¿¼ë¦¬ì— ì‚¬ìš©ëœ íšŒì‚¬ ID: {company_ids}")
                                if 'ì— íŠ¸ë¡ ' not in company_ids:
                                    print(f"[ê²½ê³ ] ì— íŠ¸ë¡ ì´ ì¿¼ë¦¬ì—ì„œ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                    logging.error("ì— íŠ¸ë¡ ì´ WHERE ì ˆì— í¬í•¨ë˜ì§€ ì•ŠìŒ!")
                        
                        # ì¿¼ë¦¬ ì‚¬ì „ ê²€ì¦ (v3)
                        warnings = self._validate_query(query_text)
                        if warnings:
                            print("[ê²€ì¦]")
                            for warning in warnings:
                                print(f"  {warning}")
                            print()
                        
                        result = self.run_cypher_query(**tool_args)
                        
                        # [í™˜ê° ë°©ì§€] ë°ì´í„° ì—†ìŒ ì‹œ ì¦‰ì‹œ ë‹µë³€ ìƒì„± (LLM ìš°íšŒ)
                        if result.get("status") == "no_data":
                            print(f"[ì™„ë£Œ] ì¡°íšŒ ê²°ê³¼ 0ê±´ (ë°ì´í„° ì—†ìŒ)")
                            logging.warning("ì¿¼ë¦¬ ì„±ê³µ, ê²°ê³¼ 0ê±´ - í™˜ê° ë°©ì§€ ëª¨ë“œ")
                            
                            # [í•µì‹¬] LLMì„ ê±°ì¹˜ì§€ ì•Šê³  ì§ì ‘ ë‹µë³€ ìƒì„± (í™˜ê° ë¶ˆê°€ëŠ¥!)
                            # ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ìš”ì²­í•œ í•­ëª© ì¶”ì¶œ (ê°„ë‹¨í•œ íŒ¨í„´)
                            requested_items = []
                            if "í˜„ê¸ˆíë¦„" in user_query:
                                requested_items.append("í˜„ê¸ˆíë¦„ ê´€ë ¨ ë°ì´í„°")
                            if "EBITDA" in user_query.upper():
                                requested_items.append("EBITDA ë°ì´í„°")
                            if "ìš´ì „ìë³¸" in user_query:
                                requested_items.append("ìš´ì „ìë³¸ ê´€ë ¨ ë°ì´í„°")
                            if "ROE" in user_query.upper() or "ROA" in user_query.upper():
                                requested_items.append("ROE/ROA ë°ì´í„°")
                            
                            items_text = ", ".join(requested_items) if requested_items else "ìš”ì²­í•˜ì‹  ë°ì´í„°"
                            
                            final_answer = f"""ì£„ì†¡í•©ë‹ˆë‹¤. {items_text}ëŠ” í˜„ì¬ Knowledge Graphì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

ì¡°íšŒí•œ ì¿¼ë¦¬ëŠ” ë¬¸ë²•ì ìœ¼ë¡œ ì •í™•í–ˆìœ¼ë‚˜, í•´ë‹¹ ë°ì´í„°ê°€ ì¬ë¬´ì œí‘œì— í¬í•¨ë˜ì–´ ìˆì§€ ì•Šì•„ ê²°ê³¼ê°€ 0ê±´ ë°˜í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.

í˜„ì¬ ì¡°íšŒ ê°€ëŠ¥í•œ ì£¼ìš” í•­ëª©:
- ì¬ë¬´ ì§€í‘œ: ë§¤ì¶œì•¡, ì˜ì—…ì´ìµ, ë‹¹ê¸°ìˆœì´ìµ, ë§¤ì¶œì´ì´ìµ
- ìì‚° í•­ëª©: ìì‚°ì´ê³„, ìœ ë™ìì‚°, ë¹„ìœ ë™ìì‚°, í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°
- ë¶€ì±„ ë° ìë³¸: ë¶€ì±„ì´ê³„, ìê¸°ìë³¸, ì°¨ì…ê¸ˆ
- ì†ìµ í•­ëª©: ì˜ì—…ì™¸ìˆ˜ìµ, ì˜ì—…ì™¸ë¹„ìš©, ë²•ì¸ì„¸ë¹„ìš©, ê°ê°€ìƒê°ë¹„

ë‹¤ë¥¸ í•­ëª©ìœ¼ë¡œ ë„ì™€ë“œë¦´ê¹Œìš”?"""
                            
                            print(f"\n[GMIS Agent v4]")
                            print(f"\n{final_answer}\n")
                            
                            # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
                            self.chat_history.append({"role": "user", "content": user_query})
                            self.chat_history.append({"role": "assistant", "content": final_answer})
                            
                            logging.info("ë°ì´í„° ì—†ìŒ - ì§ì ‘ ë‹µë³€ ìƒì„± (í™˜ê° ì°¨ë‹¨)")
                            return  # ì¦‰ì‹œ ì¢…ë£Œ (LLMì—ê²Œ ê¸°íšŒë¥¼ ì£¼ì§€ ì•ŠìŒ!)
                        
                        if result.get("status") == "error":
                            print(f"[ì¿¼ë¦¬ ì˜¤ë¥˜] {result.get('error_type')}: {result.get('error')[:200]}")
                            if result.get("hints"):
                                for hint in result["hints"]:
                                    print(f"  - {hint}")
                            print("[ì‹œìŠ¤í…œ] LLMì´ ì¿¼ë¦¬ë¥¼ ìˆ˜ì •í•˜ì—¬ ì¬ì‹œë„í•©ë‹ˆë‹¤...\n")
                            
                            # ì¬ì‹œë„ ì•ˆë‚´ (v3)
                            retry_guidance = f"""
[CRITICAL ERROR] Previous Cypher query FAILED.

Error Type: {result.get('error_type')}
Error Message: {result.get('error')[:300]}

Hints:
{chr(10).join('- ' + h for h in result.get('hints', []))}

Please analyze the error carefully and generate a CORRECTED Cypher query.
Remember:
- Use c.id not c.name for Company
- Use fs.id CONTAINS 'YYYY' not fs.year
- Korean Account IDs: 'ë§¤ì¶œì•¡_í•©ê³„', 'ì˜ì—…ì´ìµ'
- CORPORATE level: NO v.region filter
"""
                            # [ê°œì„ : ëª…ì‹œì  ì¬ì‹œë„ ì•ˆë‚´]
                            logging.error(f"ì¿¼ë¦¬ ì‹¤íŒ¨, ì¬ì‹œë„ ìœ ë„: {result.get('error_type')}")
                            current_prompt = retry_guidance  # ëª…ì‹œì ìœ¼ë¡œ ìˆ˜ì • ê°€ì´ë“œ ì „ë‹¬
                            continue
                            
                        else:
                            data_count = len(result.get('data', []))
                            print(f"[ì™„ë£Œ] {data_count}ê°œ ë ˆì½”ë“œ ì¡°íšŒ")
                            logging.info(f"ì¿¼ë¦¬ ì„±ê³µ: {data_count}ê°œ ë ˆì½”ë“œ")
                            
                            # í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼: ì‹¤ì œ ë°ì´í„°ëŠ” ìºì‹±, ë©”íƒ€ë°ì´í„°ë§Œ íˆìŠ¤í† ë¦¬
                            if data_count > 0:
                                # ì‹¤ì œ ë°ì´í„° ìºì‹± (ì‹œê°í™”/CSV ë‹¤ìš´ë¡œë“œìš©)
                                self.last_query_result = {
                                    "data": result.get("data"),
                                    "columns": list(result['data'][0].keys()),
                                    "record_count": data_count,
                                    "query_text": user_query
                                }
                                logging.debug(f"ë°ì´í„° ìºì‹± ì™„ë£Œ ({data_count}ê°œ ë ˆì½”ë“œ)")
                                
                                # íˆìŠ¤í† ë¦¬ì—ëŠ” ë©”íƒ€ë°ì´í„°ë§Œ (í† í° íš¨ìœ¨ì„±)
                                self.chat_history.append({
                                    "role": "system",
                                    "content": f"[ì¿¼ë¦¬ ì‹¤í–‰ ì™„ë£Œ] {data_count}ê°œ ë ˆì½”ë“œ ì¡°íšŒ (ì»¬ëŸ¼: {', '.join(list(result['data'][0].keys()))})"
                                })

                            
                            # ìƒ˜í”Œ ë°ì´í„° êµ¬ì¡°í™” ì¶œë ¥
                            if data_count > 0:
                                sample = result['data'][0]
                                keys = list(sample.keys())
                                print(f"[ì»¬ëŸ¼] {', '.join(keys)}")
                                print(f"[ìƒ˜í”Œ] {sample}\n")
                                
                                result['data_summary'] = {
                                    "record_count": data_count,
                                    "columns": keys,
                                    "first_record": sample
                                }
                    
                    elif tool_name == "data_visualization":
                        print("[ì‘ì—…] ì°¨íŠ¸ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
                        result = self.data_visualization(**tool_args)
                        if result.get("status") == "success":
                            file_path = result['file_path']
                            image_base64 = result.get('image_base64')
                            print(f"[ì™„ë£Œ] ì°¨íŠ¸ ì €ì¥: {file_path}\n")
                            
                            # ì°¨íŠ¸ ì •ë³´ë¥¼ ìºì‹œì— ì €ì¥ (íŒŒì‹± ì‹œ ì‚¬ìš©)
                            self.last_chart_data = {
                                "file_path": file_path,
                                "image_base64": image_base64
                            }
                            
                            # ê°„ê²°í•œ í™•ì¸ ë©”ì‹œì§€ë§Œ ìš”ì²­
                            current_prompt = f"""The data_visualization tool successfully created a chart.

Your ONLY job now is to inform the user that the chart has been created.
Just say: "ìš”ì²­í•˜ì‹  ì°¨íŠ¸ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤."

Keep it simple and short.
"""
                            continue
                        else:
                            print(f"[ì˜¤ë¥˜] {result.get('error')}\n")
                            current_prompt = f"Chart generation failed: {result.get('error')}. Inform the user."
                            continue
                            
                    elif tool_name == "generate_downloadable_link":
                        print("[ì‘ì—…] íŒŒì¼ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
                        result = self.generate_downloadable_link(**tool_args)
                        if result.get("status") == "success":
                            file_path = result['file_path']
                            print(f"[ì™„ë£Œ] íŒŒì¼ ì €ì¥: {file_path}\n")
                            # ê°„ê²°í•œ í™•ì¸ ë©”ì‹œì§€ë§Œ ìš”ì²­
                            current_prompt = f"""File successfully saved.
Path: {file_path}

Inform the user that the file has been created. Simple confirmation only.
"""
                            continue
                        else:
                            print(f"[ì˜¤ë¥˜] {result.get('error')}\n")
                            current_prompt = f"File creation failed: {result.get('error')}. Inform the user."
                            continue
                    
                    elif tool_name == "calculate_financial_ratio":
                        print("[ì‘ì—…] ì¬ë¬´ë¹„ìœ¨ì„ ê³„ì‚°í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
                        result = self.calculate_financial_ratio(**tool_args)
                        if result.get("status") == "success":
                            print(f"[ì™„ë£Œ] {result['ratio_name']}: {result['value']}{result.get('unit', '')}\n")
                            current_prompt = f"""Financial ratio calculated successfully:

Ratio: {result['ratio_name']}
Value: {result['value']}{result.get('unit', '')}
Formula: {result.get('formula', '')}
Components used: {result.get('components', {})}

Present this result to the user clearly, including the calculation details.
"""
                        else:
                            print(f"[ì˜¤ë¥˜] {result.get('message')}\n")
                            current_prompt = f"Calculation failed: {result.get('message')}. Inform the user."
                        continue
                    
                    elif tool_name == "get_definition":
                        print("[ì‘ì—…] ìš©ì–´ ì •ì˜ë¥¼ ì¡°íšŒí•˜ê³  ìˆìŠµë‹ˆë‹¤...")
                        result = self.get_definition(**tool_args)
                        if result.get("found"):
                            print(f"[ì™„ë£Œ] {result['official_name']} ì •ì˜ ì°¾ìŒ\n")
                            current_prompt = f"""Definition found in config.json:

Term: {result['official_name']}
Type: {result.get('type')}
Description: {result.get('description')}
{f"Formula: {result.get('formula')}" if result.get('formula') else ""}

Present this definition to the user. This is our system's official definition, so it's more accurate than general knowledge.
"""
                        else:
                            print(f"[ì •ë³´] Configì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ. ì¼ë°˜ ì§€ì‹ ì‚¬ìš©\n")
                            # Fallback to general_knowledge_qa
                            knowledge_answer = self.general_knowledge_qa(tool_args.get("term", user_query))
                            current_prompt = f"""Definition not in config, but here's general knowledge:

{knowledge_answer}

Present this to the user.
"""
                        continue
                    
                    elif tool_name == "get_ratios_by_viewpoint":
                        print("[ì‘ì—…] ë¶„ì„ ê´€ì ë³„ ë¹„ìœ¨ ëª©ë¡ì„ ì¡°íšŒí•˜ê³  ìˆìŠµë‹ˆë‹¤...")
                        result = self.get_ratios_by_viewpoint(**tool_args)
                        if result.get("found"):
                            ratios_list = "\n".join([f"- {r['name']} ({r['type']})" for r in result['ratios']])
                            print(f"[ì™„ë£Œ] {result['viewpoint']} ê´€ì  ë¹„ìœ¨ {result['count']}ê°œ ì°¾ìŒ\n")
                            current_prompt = f"""Found {result['count']} ratios for {result['viewpoint']} viewpoint:

{ratios_list}

Present this list to the user. You can also ask which specific ratio they want to analyze.
"""
                        else:
                            print(f"[ì •ë³´] {result.get('message')}\n")
                            current_prompt = f"Viewpoint not found: {result.get('message')}. Inform the user."
                        continue
                    
                    elif tool_name == "general_knowledge_qa":
                        print("[ì‘ì—…] ì¬ë¬´/ê²½ì˜ ì§€ì‹ì„ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
                        question = tool_args.get("question", user_query)
                        knowledge_answer = self.general_knowledge_qa(question)
                        result = {"status": "success", "answer": knowledge_answer}
                        print(f"[ì™„ë£Œ] ì§€ì‹ ë‹µë³€ ìƒì„±\n")
                        # ì§€ì‹ ë‹µë³€ì€ ê·¸ ìì²´ê°€ ìµœì¢… ë‹µë³€
                        current_prompt = f"""General knowledge answer retrieved:

{knowledge_answer}

Present this information to the user in a clear and helpful way. No special format needed.
"""
                        continue
                    
                    else:
                        result = {"error": f"Unknown tool: {tool_name}"}
                        logging.error(f"ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬: {tool_name}")
                    
                    # [í•µì‹¬ ê°œì„ ] Python ì‚¬ì „ ì§‘ê³„: LLM ë¶€ë‹´ ê°ì†Œ
                    if tool_name == "run_cypher_query" and result.get("status") == "success" and result.get("data"):
                        print("[DEBUG] ë°ì´í„° ì‚¬ì „ ì§‘ê³„ ì‹œì‘...")
                        
                        try:
                            # [ì•ˆì •ì„± ê°œì„ ] ì „ì²´ ë°ì´í„° ì²˜ë¦¬ë¥¼ try-exceptë¡œ ë³´í˜¸
                            df = pd.DataFrame(result["data"])
                            
                            # ë°ì´í„°í”„ë ˆì„ ì •ë³´ ë¡œê¹…
                            record_count = len(df)
                            mem_usage = df.memory_usage(deep=True).sum() / (1024 * 1024)  # MB ë‹¨ìœ„
                            columns = list(df.columns)
                            print(f"[DEBUG] DataFrame ìƒì„± ì™„ë£Œ. ë ˆì½”ë“œ: {record_count}ê°œ, ë©”ëª¨ë¦¬: {mem_usage:.2f} MB")
                            print(f"[DEBUG] ì»¬ëŸ¼: {columns}")
                            logging.info(f"Pythonì—ì„œ {record_count}ê°œ ë ˆì½”ë“œ ì‚¬ì „ ì§‘ê³„ ì‹œì‘ (ë©”ëª¨ë¦¬: {mem_usage:.2f} MB, ì»¬ëŸ¼: {columns})")
                            
                            # ì»¬ëŸ¼ëª… í‘œì¤€í™” (LLMì´ ë‹¤ì–‘í•œ ë³„ì¹­ ì‚¬ìš© ê°€ëŠ¥)
                            # 1. ë™ì  ê°ì§€
                            company_col = None
                            if 'c.name' in df.columns:
                                company_col = 'c.name'
                            elif 'company_name' in df.columns:
                                company_col = 'company_name'
                            elif 'company' in df.columns:
                                company_col = 'company'
                            
                            account_col = None
                            if 'a.name' in df.columns:
                                account_col = 'a.name'
                            elif 'account_name' in df.columns:
                                account_col = 'account_name'
                            elif 'account' in df.columns:
                                account_col = 'account'
                            
                            # 2. í‘œì¤€ ì´ë¦„ìœ¼ë¡œ rename (ì½”ë“œ ë‹¨ìˆœí™”)
                            rename_mapping = {}
                            if company_col and company_col != 'c.name':
                                rename_mapping[company_col] = 'c.name'
                            if account_col and account_col != 'a.name':
                                rename_mapping[account_col] = 'a.name'
                            
                            # ê¸°íƒ€ ì‹œê°„ ê´€ë ¨ ì»¬ëŸ¼ë„ í‘œì¤€í™”
                            if 'year' in df.columns and 'p.year' not in df.columns:
                                rename_mapping['year'] = 'p.year'
                            if 'month' in df.columns and 'p.month' not in df.columns:
                                rename_mapping['month'] = 'p.month'
                            if 'value' in df.columns and 'v.value' not in df.columns and 'plan' not in df.columns:
                                rename_mapping['value'] = 'v.value'
                            
                            if rename_mapping:
                                df.rename(columns=rename_mapping, inplace=True)
                                logging.info(f"ì»¬ëŸ¼ëª… í‘œì¤€í™” ì™„ë£Œ: {rename_mapping}")
                            else:
                                logging.info(f"ì»¬ëŸ¼ëª…ì´ ì´ë¯¸ í‘œì¤€ í˜•ì‹ì…ë‹ˆë‹¤")
                            
                            # ë¹ˆ ë°ì´í„° ì²´í¬
                            if record_count == 0:
                                print("[DEBUG] ë ˆì½”ë“œê°€ ì—†ì–´ ì‚¬ì „ ì§‘ê³„ ê±´ë„ˆëœ€.")
                                logging.warning("ì¿¼ë¦¬ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ")
                                current_prompt = "Query returned no data. Please inform the user that no data was found."
                                continue
                            
                            # ë©”ëª¨ë¦¬ ì„ê³„ê°’ ì²´í¬ (100MB ì´ìƒì´ë©´ ê²½ê³ )
                            if mem_usage > 100:
                                logging.warning(f"ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì¤‘: {mem_usage:.2f} MB")
                                print(f"[ê²½ê³ ] ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì¤‘: {mem_usage:.2f} MB")
                            
                            # [í•µì‹¬ ìˆ˜ì •] ë°ì´í„° íƒ€ì… íŒë‹¨ (CORPORATE vs SEGMENT)
                            is_corporate_data = 'c.name' in columns and 'a.name' in columns
                            is_segment_data = 'bs.name' in columns or 'ì†Œì†' in columns or 'ì‚¬ì—…ëª©ë¡' in columns
                            
                            if is_segment_data and not is_corporate_data:
                                # SEGMENT ë°ì´í„°ëŠ” ì§‘ê³„í•˜ì§€ ì•Šê³  ë°”ë¡œ ì „ë‹¬
                                print("[DEBUG] SEGMENT ë°ì´í„° ê°ì§€ - ì§‘ê³„ ê±´ë„ˆëœ€")
                                logging.info("SEGMENT ë ˆë²¨ ë°ì´í„° - ì‚¬ì „ ì§‘ê³„ ìƒëµ")
                                
                                # ê°„ë‹¨í•œ CSVë¡œ ë³€í™˜ë§Œ
                                data_csv = df.to_csv(index=False)
                                tool_result_text = f"""
[SEGMENT Data - No Pre-processing]

The query returned SEGMENT-level data (business units/items).
This data structure is different from CORPORATE data.

Raw data (CSV format):
```csv
{data_csv}
```

Please present this data to the user in a clear, organized way.
For list queries (ì‚¬ì—… ëª©ë¡), use bullet points.
For numerical queries, use tables.
"""
                                logging.info("SEGMENT ë°ì´í„° ì „ë‹¬ ì¤€ë¹„ ì™„ë£Œ")
                                current_prompt = tool_result_text
                                continue
                            
                            # 1. ì§€ëŠ¥ì  ì—°ê°„ ìš”ì•½ ë°ì´í„° ì§‘ê³„ (CORPORATE ì „ìš©!)
                            print("[DEBUG] 1. ì—°ê°„ ìš”ì•½ ì§‘ê³„ ì‹œì‘ (CORPORATE ë°ì´í„°)...")
                        except Exception as df_error:
                            print(f"[CRITICAL] DataFrame ìƒì„± ì‹¤íŒ¨: {df_error}")
                            logging.error(f"DataFrame ìƒì„± ì‹¤íŒ¨: {df_error}", exc_info=True)
                            current_prompt = f"Failed to process query results: {df_error}. Please inform the user."
                            continue
                        
                        # ìš”ì•½ ì§‘ê³„ (CORPORATE ì „ìš©)
                        try:
                            # configì—ì„œ ê³„ì •ë³„ ì§‘ê³„ ê·œì¹™ ê°€ì ¸ì˜¤ê¸°
                            account_agg_map = {
                                data['official_name']: data.get('aggregation', 'SUM')
                                for _, data in self.config.get('entities', {}).get('accounts', {}).items()
                            }
                            
                            # ì§‘ê³„ ê·œì¹™ ë§¤í•‘
                            df['aggregation_type'] = df['a.name'].map(account_agg_map)
                            
                            # SUMê³¼ LAST ë°ì´í„° ë¶„ë¦¬
                            df_sum = df[df['aggregation_type'] == 'SUM'].copy() if 'SUM' in df['aggregation_type'].values else pd.DataFrame()
                            df_last = df[df['aggregation_type'] == 'LAST'].copy() if 'LAST' in df['aggregation_type'].values else pd.DataFrame()
                            
                            # ì§‘ê³„í•  ê°’ ì»¬ëŸ¼ì„ ë™ì ìœ¼ë¡œ ê²°ì •
                            value_columns = []
                            calculation_columns = ['variance_pct', 'achievement_rate', 'ytd_total', 'quarterly_value']
                            
                            for col in df.columns:
                                if col in calculation_columns:
                                    continue  # ì´ë¯¸ ê³„ì‚°ëœ ì»¬ëŸ¼ì€ ì§‘ê³„í•˜ì§€ ì•ŠìŒ
                                if 'value' in col.lower() or col in ['plan', 'actual']:
                                    value_columns.append(col)
                            
                            if not value_columns:
                                raise ValueError("ì§‘ê³„í•  ê°’ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            
                            print(f"[DEBUG] ê°ì§€ëœ ê°’ ì»¬ëŸ¼: {value_columns}")
                            logging.info(f"ë™ì  ì»¬ëŸ¼ ê°ì§€: {value_columns}")
                            
                            summary_parts = []
                            
                            # SUM í•­ëª© ì§‘ê³„ (IS ê³„ì •: ë§¤ì¶œ, ì˜ì—…ì´ìµ ë“±)
                            if not df_sum.empty:
                                # ì—°ë„ë³„ë¡œ êµ¬ë¶„í•˜ì—¬ ì§‘ê³„
                                group_cols = [col for col in ['c.name', 'p.year', 'a.name', 'statement_scope'] if col in df_sum.columns]
                                # ì¡´ì¬í•˜ëŠ” ê°’ ì»¬ëŸ¼ë§Œ ì§‘ê³„
                                sum_value_cols = [col for col in value_columns if col in df_sum.columns]
                                if sum_value_cols:
                                    summary_sum = df_sum.groupby(group_cols)[sum_value_cols].sum().reset_index()
                                    summary_parts.append(summary_sum)
                                    logging.info(f"SUM ì§‘ê³„ ì™„ë£Œ: {len(df_sum)}ê°œ ë ˆì½”ë“œ â†’ {len(summary_sum)}ê°œ ì—°ë„ë³„ ì§‘ê³„ (ì»¬ëŸ¼: {sum_value_cols})")
                            
                            # LAST í•­ëª© ì§‘ê³„ (BS ê³„ì •: ìì‚°, ë¶€ì±„, ìê¸°ìë³¸ ë“±)
                            if not df_last.empty:
                                # ì—°ë„ì™€ ì›” ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ í›„ ê·¸ë£¹ë³„ ë§ˆì§€ë§‰ ê°’ ì„ íƒ
                                group_cols = [col for col in ['c.name', 'p.year', 'a.name', 'statement_scope'] if col in df_last.columns]
                                last_value_cols = [col for col in value_columns if col in df_last.columns]
                                summary_last = df_last.sort_values(['p.year', 'p.month']).groupby(group_cols, as_index=False).last()
                                keep_cols = group_cols + last_value_cols
                                summary_last = summary_last[[col for col in keep_cols if col in summary_last.columns]]
                                summary_parts.append(summary_last)
                                logging.info(f"LAST ì§‘ê³„ ì™„ë£Œ: {len(df_last)}ê°œ ë ˆì½”ë“œ â†’ {len(summary_last)}ê°œ ì—°ë„ë³„ ê¸°ë§ê°’ (ì»¬ëŸ¼: {last_value_cols})")
                            
                            # ê²°ê³¼ ë³‘í•©
                            if summary_parts:
                                summary_df = pd.concat(summary_parts, ignore_index=True)
                                # ëª¨ë“  ìˆ«ì ê°’ ì»¬ëŸ¼ì— í˜•ì‹ ì ìš©
                                for col in value_columns:
                                    if col in summary_df.columns:
                                        summary_df[col] = summary_df[col].apply(lambda x: f"{x:,.0f}" if isinstance(x, (int, float)) else x)
                                summary_md = summary_df.to_markdown(index=False)
                                logging.info("ì§€ëŠ¥ì  ì§‘ê³„ ì™„ë£Œ (SUM/LAST ê·œì¹™, ë™ì  ì»¬ëŸ¼)")
                            else:
                                summary_md = "ì§‘ê³„ ë¶ˆê°€"
                            print("[DEBUG] 1. ì—°ê°„ ìš”ì•½ ì§‘ê³„ ì™„ë£Œ.")
                        except Exception as e:
                            print(f"[ERROR] ìš”ì•½ ì§‘ê³„ ì‹¤íŒ¨: {e}")
                            logging.warning(f"ìš”ì•½ ì§‘ê³„ ì‹¤íŒ¨: {e}", exc_info=True)
                            summary_md = str(df.head())
                        
                        # 2. ì›”ë³„ ìƒì„¸ ë°ì´í„° (PIVOT ì‹œë„)
                        print("[DEBUG] 2. ì›”ë³„ ìƒì„¸ ë°ì´í„° ê°€ê³µ ì‹œì‘...")
                        try:
                            # ì—°ë„ê°€ ì—¬ëŸ¬ ê°œì¸ì§€ í™•ì¸
                            has_multiple_years = 'p.year' in df.columns and len(df['p.year'].unique()) > 1
                            
                            if len(df['c.name'].unique()) > 1:
                                # ë‹¤ì¤‘ íšŒì‚¬: PIVOT í…Œì´ë¸”
                                # ì—°ë„ê°€ ì—¬ëŸ¬ ê°œë©´ indexì— year í¬í•¨
                                index_cols = ['p.year', 'p.month'] if has_multiple_years else ['p.month']
                                pivot_df = df.pivot_table(
                                    index=index_cols, 
                                    columns=['c.name', 'a.name'], 
                                    values='v.value', 
                                    aggfunc='sum'
                                )
                                monthly_csv = pivot_df.to_csv()
                                monthly_format = "PIVOT_CSV"
                            else:
                                # ë‹¨ì¼ íšŒì‚¬: ì¼ë°˜ CSV
                                # year ì»¬ëŸ¼ì„ í¬í•¨
                                monthly_csv = df.to_csv(index=False)
                                monthly_format = "CSV"
                            print("[DEBUG] 2. ì›”ë³„ ìƒì„¸ ë°ì´í„° ê°€ê³µ ì™„ë£Œ.")
                        except Exception as e:
                            print(f"[ERROR] ì›”ë³„ ë°ì´í„° ê°€ê³µ ì‹¤íŒ¨: {e}")
                            logging.warning(f"PIVOT ì‹¤íŒ¨: {e}, ì¼ë°˜ CSV ì‚¬ìš©", exc_info=True)
                            monthly_csv = df.to_csv(index=False)
                            monthly_format = "CSV"
                        
                        # 3. LLMì—ê²Œ ê°€ê³µëœ ë°ì´í„° ì „ë‹¬
                        print("[DEBUG] 3. LLM í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹œì‘...")
                        tool_result_text = f"""
[Pre-processed Data]

**Annual Summary (Pre-aggregated):**
Use this for sections 1 and 2 (ìš”ì•½, ì§‘ê³„ ë°ì´í„°):
```markdown
{summary_md}
```

**Monthly Details ({monthly_format}):**
Use this for section 3 (ì›”ë³„ ìƒì„¸):
```csv
{monthly_csv}
```

These are pre-calculated by Python with correct SUM/LAST rules.
Now generate your COMPLETE 4-part answer:
1. ìš”ì•½
2. ì§‘ê³„ ë°ì´í„°
3. ì›”ë³„ ìƒì„¸
4. ì¸ì‚¬ì´íŠ¸ + ğŸ’¡ ê¸°ë³¸ê°’ ì•ˆë‚´
"""
                        print("[DEBUG] 3. LLM í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ.")
                        logging.info(f"ì‚¬ì „ ì§‘ê³„ ì™„ë£Œ: ìš”ì•½ + {monthly_format}")
                        current_prompt = tool_result_text
                        continue
                
                # ìµœì¢… ë‹µë³€
                elif hasattr(part, 'text') and part.text:
                    final_answer = part.text
                    
                    # ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ìš”ì•½ê³¼ ì¸ì‚¬ì´íŠ¸ ì œê±° (ì†ë„ ìµœì í™”)
                    if self._batch_test_mode:
                        import re
                        # ì„¹ì…˜ 1 (ìš”ì•½) ì œê±°
                        final_answer = re.sub(r'###\s*1\.\s*ìš”ì•½.*?(?=###|$)', '', final_answer, flags=re.DOTALL)
                        # ì„¹ì…˜ 4 (ì¸ì‚¬ì´íŠ¸) ì œê±°  
                        final_answer = re.sub(r'###\s*4\.\s*ì¸ì‚¬ì´íŠ¸.*?(?=###|$)', '', final_answer, flags=re.DOTALL)
                        # ğŸ’¡ ì•ˆë‚´ ì œê±°
                        final_answer = re.sub(r'ğŸ’¡.*?(?=\n|$)', '', final_answer, flags=re.MULTILINE)
                        # ê³µë°± ì •ë¦¬
                        final_answer = re.sub(r'\n\n\n+', '\n\n', final_answer).strip()
                    
                    # ë‹µë³€ í’ˆì§ˆ ê²€ì¦
                    quality_score = self._validate_answer_format(final_answer)
                    
                    print(f"\n[GMIS Agent v4]")
                    if not self._batch_test_mode and quality_score < 2:
                        print("[í’ˆì§ˆ ê²½ê³ ] ë‹µë³€ì´ GENEROUS ì „ëµì„ ë”°ë¥´ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                        logging.warning("ë‹µë³€ í’ˆì§ˆ ì ìˆ˜ ë‚®ìŒ")
                    print(f"\n{final_answer}\n")
                    
                    # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸ (ë©”íƒ€ë°ì´í„°ìš© - ì‹¤ì œ ëŒ€í™”ëŠ” chat ê°ì²´ê°€ ê´€ë¦¬)
                    self.chat_history.append({"role": "user", "content": user_query})
                    self.chat_history.append({"role": "assistant", "content": final_answer})
                    
                    # [ê¸´ê¸‰ ìˆ˜ì •] chat íˆìŠ¤í† ë¦¬ ê´€ë¦¬ - ì™„í™”ëœ ê¸°ì¤€
                    # Gemini chat íˆìŠ¤í† ë¦¬ ê¸¸ì´ ì²´í¬
                    if self.chat and hasattr(self.chat, 'history'):
                        chat_history_count = len(self.chat.history)
                        logging.info(f"í˜„ì¬ chat íˆìŠ¤í† ë¦¬: {chat_history_count}ê°œ ë©”ì‹œì§€")
                        
                        # 30ê°œ ë©”ì‹œì§€ (15í„´) ì´ˆê³¼ ì‹œë§Œ ì¬ì´ˆê¸°í™” (ì™„í™”!)
                        if chat_history_count > 30:
                            logging.warning(f"chat íˆìŠ¤í† ë¦¬ {chat_history_count}ê°œ ì´ˆê³¼ â†’ ì¬ì´ˆê¸°í™”")
                            print(f"[ì‹œìŠ¤í…œ] ëŒ€í™”ê°€ ê¸¸ì–´ì ¸ íˆìŠ¤í† ë¦¬ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤...")
                            # [ì•ˆì „í•œ ì¬ì´ˆê¸°í™”] ë°”ë¡œ Noneìœ¼ë¡œ í•˜ì§€ ì•Šê³  ëª…ì‹œì ìœ¼ë¡œ ì²˜ë¦¬
                            try:
                                self.chat = self.model.start_chat(
                                    history=[
                                        {'role': 'user', 'parts': [self.system_prompt]},
                                        {'role': 'model', 'parts': ["OK. I am GMIS Agent v4. Ready."]}
                                    ],
                                    enable_automatic_function_calling=False
                                )
                                self.chat_history = self.chat_history[-6:]  # ìµœê·¼ 3í„´ë§Œ ìœ ì§€
                                logging.info("chat ê°ì²´ ì¬ìƒì„± ì™„ë£Œ")
                            except Exception as reset_error:
                                logging.error(f"chat ì¬ìƒì„± ì‹¤íŒ¨: {reset_error}")
                                # ì‹¤íŒ¨í•˜ë©´ ê·¸ëƒ¥ ìœ ì§€
                    
                    logging.info("ìµœì¢… ë‹µë³€ ìƒì„± ì™„ë£Œ")
                    return
                
                else:
                    print("[ê²½ê³ ] ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ í˜•ì‹")
                    logging.warning("ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ í˜•ì‹")
                    break
            
            print("[ê²½ê³ ] ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬")
            logging.warning(f"ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜({self.max_iterations}) ë„ë‹¬")
            print("[ê²½ê³ ] ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            print(f"\n[ERROR] Agent ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            logging.error(f"Agent ì‹¤í–‰ ì˜¤ë¥˜: {e}", exc_info=True)
            import traceback
            traceback.print_exc()
            # ì˜¤ë¥˜ë¥¼ ë‹¤ì‹œ ë˜ì§€ì§€ ì•ŠìŒ (mainì˜ exceptì—ì„œ ì²˜ë¦¬)
    
    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.driver:
            self.driver.close()
            print("\n[ì—°ê²°ì¢…ë£Œ] Neo4j ì—°ê²° ì¢…ë£Œ")
            logging.info("Neo4j ì—°ê²° ì¢…ë£Œ")

if __name__ == "__main__":
    print("="*70)
    print("  GMIS Agent v4 Final - Knowledge Graph v5")
    print("="*70)
    print()
    
    agent = None
    try:
        agent = GmisAgentV4()
        print("ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. (ì¢…ë£Œ: 'exit')\n")
        
        question_count = 0  # ì§ˆë¬¸ ì¹´ìš´í„°
        
        while True:
            try:
                # [ê¸´ê¸‰ ìˆ˜ì •] ì…ë ¥ ë°›ê¸° ì „ ìƒíƒœ ì•ˆì •í™”
                question_count += 1
                logging.info(f"ì§ˆë¬¸ {question_count}ë²ˆ ëŒ€ê¸° ì¤‘...")
                
                # [ì¶”ê°€] ë©”ëª¨ë¦¬ ê°•ì œ ì •ë¦¬ (Python GC)
                import gc
                gc.collect()
                logging.info("ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì™„ë£Œ")
                
                print(f"\n[YOU] ", end='', flush=True)  # flush ì¶”ê°€
                
                try:
                    import sys
                    # Windows í‘œì¤€ ì…ë ¥ ë²„í¼ í”ŒëŸ¬ì‹œ
                    if hasattr(sys.stdin, 'flush'):
                        try:
                            sys.stdin.flush()
                        except:
                            pass
                    
                    user_input = sys.stdin.readline().strip()  # input() ëŒ€ì‹  readline() ì‚¬ìš©
                    
                    if not user_input:
                        continue
                        
                except (EOFError, KeyboardInterrupt) as input_error:
                    print(f"\n[ì…ë ¥ ì¤‘ë‹¨] {type(input_error).__name__}")
                    logging.warning(f"ì…ë ¥ ì¤‘ë‹¨: {input_error}")
                    break
                except Exception as input_error:
                    print(f"\n[ì…ë ¥ ì˜¤ë¥˜] {type(input_error).__name__}: {input_error}")
                    logging.error(f"input() ì˜¤ë¥˜: {input_error}", exc_info=True)
                    import traceback
                    traceback.print_exc()
                    continue
                
                # [ì¶”ê°€] ì…ë ¥ ì„±ê³µ ë¡œê·¸
                logging.info(f"ì…ë ¥ ìˆ˜ì‹  ì™„ë£Œ: {user_input[:50]}...")
                print(f"[DEBUG] ì…ë ¥ ìˆ˜ì‹  ì™„ë£Œ: '{user_input}'")
                
                if user_input.lower() in ['exit', 'quit', 'ì¢…ë£Œ']:
                    logging.info("ì‚¬ìš©ì ì¢…ë£Œ ìš”ì²­")
                    break
                if not user_input.strip():
                    continue
                
                # run() í˜¸ì¶œ ì „ ì•ˆì „ ì²´í¬
                print(f"[DEBUG] run() ë©”ì„œë“œ í˜¸ì¶œ ì¤€ë¹„...")
                logging.info(f"run() í˜¸ì¶œ ì‹œì‘: {user_input}")
                
                # run() í˜¸ì¶œ ì „ì²´ë¥¼ ë³´í˜¸
                try:
                    agent.run(user_input)
                    print(f"[DEBUG] run() ë©”ì„œë“œ ì •ìƒ ì™„ë£Œ")
                    logging.info("run() ì •ìƒ ì™„ë£Œ")
                except Exception as run_error:
                    print(f"\n[ì˜¤ë¥˜ ë°œìƒ] ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {run_error}")
                    print(f"ì˜¤ë¥˜ íƒ€ì…: {type(run_error).__name__}")
                    logging.error(f"run() ì‹¤í–‰ ì˜¤ë¥˜: {run_error}", exc_info=True)
                    import traceback
                    traceback.print_exc()
                    print("\nëŒ€í™”ë¥¼ ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (ê³„ì†í•˜ë ¤ë©´ Enter, ì¢…ë£Œí•˜ë ¤ë©´ 'exit')")
                    
                    try:
                        continue_choice = input()
                        if continue_choice.lower() in ['exit', 'quit', 'ì¢…ë£Œ']:
                            break
                    except:
                        print("ì…ë ¥ ì˜¤ë¥˜. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                        break
                
                # [ì•ˆì „ì¥ì¹˜] ë©”ëª¨ë¦¬ ì •ë¦¬
                if question_count % 3 == 0:
                    logging.info(f"{question_count}ë²ˆì§¸ ì§ˆë¬¸ ì™„ë£Œ - ë©”ëª¨ë¦¬ ì •ë¦¬ ê¶Œì¥")
                    print(f"[ì‹œìŠ¤í…œ] {question_count}ë²ˆì˜ ì§ˆë¬¸ì„ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.")
                
            except Exception as loop_error:
                print(f"\n[ë£¨í”„ ì˜¤ë¥˜] ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {loop_error}")
                logging.error(f"while ë£¨í”„ ì˜¤ë¥˜: {loop_error}", exc_info=True)
                import traceback
                traceback.print_exc()
                break
                
    except KeyboardInterrupt:
        print("\n\nì‚¬ìš©ì ì¤‘ë‹¨")
    except Exception as e:
        logging.critical(f"ì¹˜ëª…ì  ì˜¤ë¥˜: {e}", exc_info=True)
        print(f"\n[ì¹˜ëª…ì  ì˜¤ë¥˜] {e}")
        import traceback
        traceback.print_exc()
    finally:
        if agent:
            agent.close()
        print("\nAgent v4ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        input("Press Enter to close...")  # í„°ë¯¸ë„ ìœ ì§€